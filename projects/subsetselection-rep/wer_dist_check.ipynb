{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shibutani/miniconda3/envs/py39/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import pandas as pd\n",
    "import torchaudio\n",
    "import librosa\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from torchmetrics.functional import char_error_rate, word_error_rate\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import copy\n",
    "import pickle\n",
    "import math\n",
    "tkwargs_int = {\n",
    "    \"dtype\": torch.int32,\n",
    "    \"device\": \"cuda\",\n",
    "}\n",
    "tkwargs_float = {\n",
    "    \"dtype\": torch.float32,\n",
    "    \"device\": \"cuda\",\n",
    "}\n",
    "# 事前に行ったFineTuningにおけるWERからサブセットセレクションに用いる平均WERを計算する\n",
    "from collections import defaultdict\n",
    "average_wers = defaultdict(list)\n",
    "scores = []\n",
    "WER_CALCULATION_EPOCH = 30\n",
    "TOTAL_RUN = 10\n",
    "for run in range(TOTAL_RUN):\n",
    "    cpt = torch.load(f\"cpts/timit_finetune_checkpoint_{run}_{WER_CALCULATION_EPOCH-1}.pt\")\n",
    "    wers = cpt[\"input_to_wer\"]\n",
    "    teachers = cpt[\"input_to_teacher\"]\n",
    "    for idx, wer in wers.items():\n",
    "        average_wers[idx].append(wer.item())\n",
    "for idx, v in average_wers.items():\n",
    "    scores.append((idx, np.mean(v)))\n",
    "with open(\"timit_wer_scores.bin\", \"wb\") as f:\n",
    "    pickle.dump(scores, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-7dc5a6ddcdc99305\n",
      "Found cached dataset timit (/home/shibutani/.cache/huggingface/datasets/timit/default-7dc5a6ddcdc99305/0.0.0/e393649805e8c068eb5c3311baf236f53ffa81289ecc57e285c6e06a31f00ba8)\n",
      "100%|██████████| 2/2 [00:00<00:00, 409.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_dataset size: 4620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4620 [00:00<?, ?ex/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "idx: 0, 46, train_teacher: She had your dark suit in greasy wash water al year., selection_techer: She had your dark suit in greasy wash water all year.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/shibutani/fs/ASR/projects/subsetselection-rep/wer_dist_check.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 102>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bsacs01/home/shibutani/fs/ASR/projects/subsetselection-rep/wer_dist_check.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=99'>100</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbase_dataset size: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(base_dataset[\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bsacs01/home/shibutani/fs/ASR/projects/subsetselection-rep/wer_dist_check.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=100'>101</a>\u001b[0m RETAIN \u001b[39m=\u001b[39m \u001b[39m0.6\u001b[39m\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bsacs01/home/shibutani/fs/ASR/projects/subsetselection-rep/wer_dist_check.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=101'>102</a>\u001b[0m random_selected_dataset \u001b[39m=\u001b[39m random_sampler(base_dataset, scores, RETAIN)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bsacs01/home/shibutani/fs/ASR/projects/subsetselection-rep/wer_dist_check.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=102'>103</a>\u001b[0m top_k_selected_dataset \u001b[39m=\u001b[39m top_k_sampler(base_dataset, scores, RETAIN)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bsacs01/home/shibutani/fs/ASR/projects/subsetselection-rep/wer_dist_check.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=103'>104</a>\u001b[0m bottom_k_selected_dataset \u001b[39m=\u001b[39m bottom_k_sampler(base_dataset, scores, RETAIN)\n",
      "\u001b[1;32m/home/shibutani/fs/ASR/projects/subsetselection-rep/wer_dist_check.ipynb Cell 2\u001b[0m in \u001b[0;36mrandom_sampler\u001b[0;34m(dataset, scores, retain)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsacs01/home/shibutani/fs/ASR/projects/subsetselection-rep/wer_dist_check.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=55'>56</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(teachers[idx])):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsacs01/home/shibutani/fs/ASR/projects/subsetselection-rep/wer_dist_check.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m         \u001b[39massert\u001b[39;00m teachers[idx][i] \u001b[39m==\u001b[39m example[\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m][i], \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39midx: \u001b[39m\u001b[39m{\u001b[39;00midx\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m, train_teacher: \u001b[39m\u001b[39m{\u001b[39;00mteachers[idx]\u001b[39m}\u001b[39;00m\u001b[39m, selection_techer: \u001b[39m\u001b[39m{\u001b[39;00mexample[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bsacs01/home/shibutani/fs/ASR/projects/subsetselection-rep/wer_dist_check.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m asr_dataset[\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mmap(checker, with_indices\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsacs01/home/shibutani/fs/ASR/projects/subsetselection-rep/wer_dist_check.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=58'>59</a>\u001b[0m asr_dataset[\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m asr_dataset[\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mshuffle()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsacs01/home/shibutani/fs/ASR/projects/subsetselection-rep/wer_dist_check.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m asr_dataset[\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m asr_dataset[\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mfilter(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsacs01/home/shibutani/fs/ASR/projects/subsetselection-rep/wer_dist_check.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=60'>61</a>\u001b[0m         \u001b[39mlambda\u001b[39;00m example, index: index \u001b[39m<\u001b[39m select_size, with_indices\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, num_proc\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsacs01/home/shibutani/fs/ASR/projects/subsetselection-rep/wer_dist_check.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=61'>62</a>\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/datasets/arrow_dataset.py:2573\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   2570\u001b[0m disable_tqdm \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m logging\u001b[39m.\u001b[39mis_progress_bar_enabled()\n\u001b[1;32m   2572\u001b[0m \u001b[39mif\u001b[39;00m num_proc \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m num_proc \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m-> 2573\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_single(\n\u001b[1;32m   2574\u001b[0m         function\u001b[39m=\u001b[39;49mfunction,\n\u001b[1;32m   2575\u001b[0m         with_indices\u001b[39m=\u001b[39;49mwith_indices,\n\u001b[1;32m   2576\u001b[0m         with_rank\u001b[39m=\u001b[39;49mwith_rank,\n\u001b[1;32m   2577\u001b[0m         input_columns\u001b[39m=\u001b[39;49minput_columns,\n\u001b[1;32m   2578\u001b[0m         batched\u001b[39m=\u001b[39;49mbatched,\n\u001b[1;32m   2579\u001b[0m         batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m   2580\u001b[0m         drop_last_batch\u001b[39m=\u001b[39;49mdrop_last_batch,\n\u001b[1;32m   2581\u001b[0m         remove_columns\u001b[39m=\u001b[39;49mremove_columns,\n\u001b[1;32m   2582\u001b[0m         keep_in_memory\u001b[39m=\u001b[39;49mkeep_in_memory,\n\u001b[1;32m   2583\u001b[0m         load_from_cache_file\u001b[39m=\u001b[39;49mload_from_cache_file,\n\u001b[1;32m   2584\u001b[0m         cache_file_name\u001b[39m=\u001b[39;49mcache_file_name,\n\u001b[1;32m   2585\u001b[0m         writer_batch_size\u001b[39m=\u001b[39;49mwriter_batch_size,\n\u001b[1;32m   2586\u001b[0m         features\u001b[39m=\u001b[39;49mfeatures,\n\u001b[1;32m   2587\u001b[0m         disable_nullable\u001b[39m=\u001b[39;49mdisable_nullable,\n\u001b[1;32m   2588\u001b[0m         fn_kwargs\u001b[39m=\u001b[39;49mfn_kwargs,\n\u001b[1;32m   2589\u001b[0m         new_fingerprint\u001b[39m=\u001b[39;49mnew_fingerprint,\n\u001b[1;32m   2590\u001b[0m         disable_tqdm\u001b[39m=\u001b[39;49mdisable_tqdm,\n\u001b[1;32m   2591\u001b[0m         desc\u001b[39m=\u001b[39;49mdesc,\n\u001b[1;32m   2592\u001b[0m     )\n\u001b[1;32m   2593\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2595\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mformat_cache_file_name\u001b[39m(cache_file_name, rank):\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/datasets/arrow_dataset.py:583\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[39mself\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    582\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 583\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    584\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[1;32m    585\u001b[0m \u001b[39mfor\u001b[39;00m dataset \u001b[39min\u001b[39;00m datasets:\n\u001b[1;32m    586\u001b[0m     \u001b[39m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/datasets/arrow_dataset.py:550\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    543\u001b[0m self_format \u001b[39m=\u001b[39m {\n\u001b[1;32m    544\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_type,\n\u001b[1;32m    545\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mformat_kwargs\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_kwargs,\n\u001b[1;32m    546\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_columns,\n\u001b[1;32m    547\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39moutput_all_columns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_all_columns,\n\u001b[1;32m    548\u001b[0m }\n\u001b[1;32m    549\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 550\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    551\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[1;32m    552\u001b[0m \u001b[39m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/datasets/fingerprint.py:480\u001b[0m, in \u001b[0;36mfingerprint_transform.<locals>._fingerprint.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m             validate_fingerprint(kwargs[fingerprint_name])\n\u001b[1;32m    478\u001b[0m \u001b[39m# Call actual function\u001b[39;00m\n\u001b[0;32m--> 480\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    482\u001b[0m \u001b[39m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[39mif\u001b[39;00m inplace:  \u001b[39m# update after calling func so that the fingerprint doesn't change if the function fails\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/datasets/arrow_dataset.py:2954\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset, disable_tqdm, desc, cache_only)\u001b[0m\n\u001b[1;32m   2952\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m batched:\n\u001b[1;32m   2953\u001b[0m     \u001b[39mfor\u001b[39;00m i, example \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(pbar):\n\u001b[0;32m-> 2954\u001b[0m         example \u001b[39m=\u001b[39m apply_function_on_filtered_inputs(example, i, offset\u001b[39m=\u001b[39;49moffset)\n\u001b[1;32m   2955\u001b[0m         \u001b[39mif\u001b[39;00m update_data:\n\u001b[1;32m   2956\u001b[0m             \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/datasets/arrow_dataset.py:2853\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[0;34m(inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   2851\u001b[0m \u001b[39mif\u001b[39;00m with_rank:\n\u001b[1;32m   2852\u001b[0m     additional_args \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (rank,)\n\u001b[0;32m-> 2853\u001b[0m processed_inputs \u001b[39m=\u001b[39m function(\u001b[39m*\u001b[39;49mfn_args, \u001b[39m*\u001b[39;49madditional_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfn_kwargs)\n\u001b[1;32m   2854\u001b[0m \u001b[39mif\u001b[39;00m update_data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2855\u001b[0m     \u001b[39m# Check if the function returns updated examples\u001b[39;00m\n\u001b[1;32m   2856\u001b[0m     update_data \u001b[39m=\u001b[39m \u001b[39misinstance\u001b[39m(processed_inputs, (Mapping, pa\u001b[39m.\u001b[39mTable))\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/datasets/arrow_dataset.py:2533\u001b[0m, in \u001b[0;36mDataset.map.<locals>.decorate.<locals>.decorated\u001b[0;34m(item, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2529\u001b[0m decorated_item \u001b[39m=\u001b[39m (\n\u001b[1;32m   2530\u001b[0m     Example(item, features\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m batched \u001b[39melse\u001b[39;00m Batch(item, features\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures)\n\u001b[1;32m   2531\u001b[0m )\n\u001b[1;32m   2532\u001b[0m \u001b[39m# Use the LazyDict internally, while mapping the function\u001b[39;00m\n\u001b[0;32m-> 2533\u001b[0m result \u001b[39m=\u001b[39m f(decorated_item, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2534\u001b[0m \u001b[39m# Return a standard dict\u001b[39;00m\n\u001b[1;32m   2535\u001b[0m \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39mdata \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(result, LazyDict) \u001b[39melse\u001b[39;00m result\n",
      "\u001b[1;32m/home/shibutani/fs/ASR/projects/subsetselection-rep/wer_dist_check.ipynb Cell 2\u001b[0m in \u001b[0;36mrandom_sampler.<locals>.checker\u001b[0;34m(example, idx)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsacs01/home/shibutani/fs/ASR/projects/subsetselection-rep/wer_dist_check.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mchecker\u001b[39m(example, idx):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsacs01/home/shibutani/fs/ASR/projects/subsetselection-rep/wer_dist_check.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=55'>56</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(teachers[idx])):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bsacs01/home/shibutani/fs/ASR/projects/subsetselection-rep/wer_dist_check.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m         \u001b[39massert\u001b[39;00m teachers[idx][i] \u001b[39m==\u001b[39m example[\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m][i], \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39midx: \u001b[39m\u001b[39m{\u001b[39;00midx\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m, train_teacher: \u001b[39m\u001b[39m{\u001b[39;00mteachers[idx]\u001b[39m}\u001b[39;00m\u001b[39m, selection_techer: \u001b[39m\u001b[39m{\u001b[39;00mexample[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: idx: 0, 46, train_teacher: She had your dark suit in greasy wash water al year., selection_techer: She had your dark suit in greasy wash water all year."
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import random\n",
    "def cowerage_sampler(dataset, scores, retain, other_size):\n",
    "    asr_dataset = copy.deepcopy(dataset)\n",
    "    sorted_scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "    highest_wer = sorted_scores[0][1]\n",
    "    lowest_wer = sorted_scores[-1][1]\n",
    "    num_buckets = int(len(sorted_scores) / 10)\n",
    "\n",
    "    buckets = []\n",
    "    for i in range(num_buckets):\n",
    "        bucket = []\n",
    "        # WERの範囲をnum_buckets等分する\n",
    "        # 等分であるため、一つもデータが含まれないbucketも存在する\n",
    "        lower_limit = lowest_wer + (\n",
    "            (i - 1) * (highest_wer - lowest_wer) / num_buckets\n",
    "        )\n",
    "        upper_limit = lowest_wer + ((i) * (highest_wer - lowest_wer) / num_buckets)\n",
    "        for score in sorted_scores:\n",
    "            if score[1] >= lower_limit and score[1] < upper_limit:\n",
    "                bucket.append(score)\n",
    "        buckets.append(bucket)\n",
    "    selected_scores_tmp = []\n",
    "    counter = 0\n",
    "    for bucket in buckets:\n",
    "        sampled = random.sample(bucket, math.ceil(retain * len(bucket)))\n",
    "        selected_scores_tmp.append(sampled)\n",
    "        counter += len(sampled)\n",
    "    # 他のサンプリング方法以下にする\n",
    "    while counter > other_size:\n",
    "        for selected_score_tmp in selected_scores_tmp:\n",
    "            if counter == other_size:\n",
    "                break\n",
    "            else:\n",
    "                if len(selected_score_tmp) > 0:\n",
    "                    selected_score_tmp.pop()\n",
    "                    counter -= 1\n",
    "    selected_scores = []\n",
    "    for selected_score_tmp in selected_scores_tmp:\n",
    "        selected_scores.extend(selected_score_tmp)\n",
    "    selected_idxs = [selected_score[0] for selected_score in selected_scores]\n",
    "    def checker(example, idx):\n",
    "        for i in range(len(teachers[idx])):\n",
    "            assert teachers[idx][i] == example[\"text\"][i], f\"idx: {idx}, {i}, train_teacher: {teachers[idx]}, selection_techer: {example['text']}\"\n",
    "    asr_dataset[\"train\"].map(checker, with_indices=True)\n",
    "    asr_dataset[\"train\"] = asr_dataset[\"train\"].filter(\n",
    "            lambda example, index: index in selected_idxs,\n",
    "            with_indices=True,\n",
    "            num_proc=16,\n",
    "    )\n",
    "    return asr_dataset\n",
    "def random_sampler(dataset, scores, retain):\n",
    "    asr_dataset = copy.deepcopy(dataset)\n",
    "    select_size = int(retain * len(asr_dataset[\"train\"]))\n",
    "    def checker(example, idx):\n",
    "        for i in range(len(teachers[idx])):\n",
    "            assert teachers[idx][i] == example[\"text\"][i], f\"idx: {idx}, {i}, train_teacher: {teachers[idx]}, selection_techer: {example['text']}\"\n",
    "    asr_dataset[\"train\"].map(checker, with_indices=True)\n",
    "    asr_dataset[\"train\"] = asr_dataset[\"train\"].shuffle()\n",
    "    asr_dataset[\"train\"] = asr_dataset[\"train\"].filter(\n",
    "            lambda example, index: index < select_size, with_indices=True, num_proc=16,\n",
    "    )\n",
    "    return asr_dataset\n",
    "\n",
    "def top_k_sampler(dataset, scores, retain):\n",
    "    asr_dataset = copy.deepcopy(dataset)\n",
    "    sorted_scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "    boundary = int(len(sorted_scores) * retain)\n",
    "    selected_scores = sorted_scores[0:boundary]\n",
    "    selected_idxs = [selected_score[0] for selected_score in selected_scores]\n",
    "    def checker(example, idx):\n",
    "        for i in range(len(teachers[idx])):\n",
    "            assert teachers[idx][i] == example[\"text\"][i], f\"idx: {idx}, {i}, train_teacher: {teachers[idx]}, selection_techer: {example['text']}\"\n",
    "    asr_dataset[\"train\"].map(checker, with_indices=True)\n",
    "    asr_dataset[\"train\"] = asr_dataset[\"train\"].filter(\n",
    "            lambda example, index: index in selected_idxs,\n",
    "            with_indices=True,\n",
    "            num_proc=16,\n",
    "    )\n",
    "    return asr_dataset\n",
    "def bottom_k_sampler(dataset, scores, retain):\n",
    "    asr_dataset = copy.deepcopy(dataset)\n",
    "    sorted_scores = sorted(scores, key=lambda x: x[1], reverse=False)\n",
    "    boundary = int(len(sorted_scores) * retain)\n",
    "    selected_scores = sorted_scores[0:boundary]\n",
    "    selected_idxs = [selected_score[0] for selected_score in selected_scores]\n",
    "    # indexが訓練時と同一であるかチェック\n",
    "    def checker(example, idx):\n",
    "        for i in range(len(teachers[idx])):\n",
    "            assert teachers[idx][i] == example[\"text\"][i], f\"idx: {idx}, {i}, train_teacher: {teachers[idx]}, selection_techer: {example['text']}\"\n",
    "    asr_dataset[\"train\"].map(checker, with_indices=True)\n",
    "    asr_dataset[\"train\"] = asr_dataset[\"train\"].filter(\n",
    "            lambda example, index: index in selected_idxs,\n",
    "            with_indices=True,\n",
    "            num_proc=16,\n",
    "    )\n",
    "    return asr_dataset\n",
    "from datasets import load_dataset\n",
    "base_dataset = load_dataset(\"../../datasets/loading_scripts/timit.py\", data_dir=\"../../datasets/TIMIT/\")\n",
    "print(f\"base_dataset size: {len(base_dataset['train'])}\")\n",
    "RETAIN = 0.6\n",
    "random_selected_dataset = random_sampler(base_dataset, scores, RETAIN)\n",
    "top_k_selected_dataset = top_k_sampler(base_dataset, scores, RETAIN)\n",
    "bottom_k_selected_dataset = bottom_k_sampler(base_dataset, scores, RETAIN)\n",
    "cowerage_selected_dataset = cowerage_sampler(base_dataset, scores, RETAIN, other_size=len(bottom_k_selected_dataset[\"train\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file': '/n/work3/shibutani/ASR/datasets/TIMIT/train/dr5/fbjl0/sa1.wav',\n",
       " 'audio': {'path': '/n/work3/shibutani/ASR/datasets/TIMIT/train/dr5/fbjl0/sa1.wav',\n",
       "  'array': array([ 6.1035156e-05,  3.0517578e-05, -3.0517578e-05, ...,\n",
       "          3.0517578e-05,  2.4414062e-04, -6.1035156e-04], dtype=float32),\n",
       "  'sampling_rate': 16000},\n",
       " 'text': 'She had your dark suit in greasy wash water all year.',\n",
       " 'phonetic_detail': {'start': [0,\n",
       "   2860,\n",
       "   5100,\n",
       "   6719,\n",
       "   7561,\n",
       "   9124,\n",
       "   9602,\n",
       "   10270,\n",
       "   11480,\n",
       "   12190,\n",
       "   12510,\n",
       "   14520,\n",
       "   15560,\n",
       "   16580,\n",
       "   16919,\n",
       "   19380,\n",
       "   21960,\n",
       "   22330,\n",
       "   22680,\n",
       "   23450,\n",
       "   24290,\n",
       "   25309,\n",
       "   25850,\n",
       "   26340,\n",
       "   27989,\n",
       "   29150,\n",
       "   31230,\n",
       "   32334,\n",
       "   34590,\n",
       "   36800,\n",
       "   38200,\n",
       "   39280,\n",
       "   39986,\n",
       "   41400,\n",
       "   41800,\n",
       "   42920,\n",
       "   44722,\n",
       "   46828,\n",
       "   47663,\n",
       "   49543,\n",
       "   51256,\n",
       "   54040],\n",
       "  'stop': [2860,\n",
       "   5100,\n",
       "   6719,\n",
       "   7561,\n",
       "   9124,\n",
       "   9602,\n",
       "   10270,\n",
       "   11480,\n",
       "   12190,\n",
       "   12510,\n",
       "   14520,\n",
       "   15560,\n",
       "   16580,\n",
       "   16919,\n",
       "   19380,\n",
       "   21960,\n",
       "   22330,\n",
       "   22680,\n",
       "   23450,\n",
       "   24290,\n",
       "   25309,\n",
       "   25850,\n",
       "   26340,\n",
       "   27989,\n",
       "   29150,\n",
       "   31230,\n",
       "   32334,\n",
       "   34590,\n",
       "   36800,\n",
       "   38200,\n",
       "   39280,\n",
       "   39986,\n",
       "   41400,\n",
       "   41800,\n",
       "   42920,\n",
       "   44722,\n",
       "   46828,\n",
       "   47663,\n",
       "   49543,\n",
       "   51256,\n",
       "   54040,\n",
       "   55840],\n",
       "  'utterance': ['h#',\n",
       "   'sh',\n",
       "   'iy',\n",
       "   'hv',\n",
       "   'ae',\n",
       "   'dcl',\n",
       "   'jh',\n",
       "   'axr',\n",
       "   'dcl',\n",
       "   'd',\n",
       "   'aa',\n",
       "   'r',\n",
       "   'kcl',\n",
       "   'k',\n",
       "   's',\n",
       "   'ux',\n",
       "   'tcl',\n",
       "   't',\n",
       "   'q',\n",
       "   'ix',\n",
       "   'ng',\n",
       "   'gcl',\n",
       "   'g',\n",
       "   'r',\n",
       "   'iy',\n",
       "   's',\n",
       "   'iy',\n",
       "   'w',\n",
       "   'aa',\n",
       "   'sh',\n",
       "   'epi',\n",
       "   'w',\n",
       "   'ao',\n",
       "   'dx',\n",
       "   'er',\n",
       "   'q',\n",
       "   'ao',\n",
       "   'l',\n",
       "   'y',\n",
       "   'ih',\n",
       "   'er',\n",
       "   'h#']},\n",
       " 'word_detail': {'start': [2860,\n",
       "   6719,\n",
       "   9602,\n",
       "   11480,\n",
       "   16919,\n",
       "   22680,\n",
       "   25309,\n",
       "   32334,\n",
       "   39280,\n",
       "   44722,\n",
       "   47663],\n",
       "  'stop': [6719,\n",
       "   10270,\n",
       "   11480,\n",
       "   16919,\n",
       "   22680,\n",
       "   25309,\n",
       "   32334,\n",
       "   38200,\n",
       "   42920,\n",
       "   47663,\n",
       "   54040],\n",
       "  'utterance': ['she',\n",
       "   'had',\n",
       "   'your',\n",
       "   'dark',\n",
       "   'suit',\n",
       "   'in',\n",
       "   'greasy',\n",
       "   'wash',\n",
       "   'water',\n",
       "   'all',\n",
       "   'year']},\n",
       " 'dialect_region': 'dr5',\n",
       " 'sentence_type': 'sa',\n",
       " 'speaker_id': 'bjl0',\n",
       " 'id': 'sa1'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_selected_dataset[\"train\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e822874ab5bf40d8e254332eebb695e7fa04bbc22c17addc03c9268ee429b8b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
