{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from data import LibriLightDataset, TEDLIUMRelease2Dataset, TEDLIUMRelease2SpecificTalkDataset\n",
    "from sampler import PhonemeKLSampler\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting vocab...\n"
     ]
    }
   ],
   "source": [
    "libri_light_dataset = LibriLightDataset(\n",
    "    subset=\"10h\",\n",
    "    identifier_to_phones_file_path=\"phones/librispeech_normalized_phones_no_bcl.json\",\n",
    "    vocab_file_path=\"vocabs/libri-light_10h.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of phones not found: 14698\n"
     ]
    }
   ],
   "source": [
    "tedlium2_dataset = TEDLIUMRelease2Dataset(\n",
    "    identifier_to_phones_file_path=\"phones/ted2_normalized_phones_no_bcl.json\",\n",
    "    subset=\"train\",\n",
    "    vocab_file_path=\"vocabs/libri-light_10h.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " tensor([-0.2830, -0.3177, -0.3274,  ..., -0.1134, -0.0843, -0.0593]),\n",
       " tensor(30720),\n",
       " tensor([26, 24,  4, 18, 16, 23, 14, 28,  2, 18,  8, 13, 28, 23, 24, 27,  5]),\n",
       " tensor(17),\n",
       " 'today because of\\n',\n",
       " ['t', 'ah', 'd', 'ey', 'b', 'ih', 'k', 'aa', 'z', 'ah', 'v'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tedlium2_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"phones/converter.json\", \"r\") as f:\n",
    "#    converter = json.load(f)\n",
    "#    unique_phones = set(converter.values())\n",
    "#phone_idx_map = {phone: idx for idx, phone in enumerate(unique_phones)}\n",
    "#with open(\"phones/phone_idx_map.json\", \"w\") as f:\n",
    "#    json.dump(phone_idx_map, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"phones/phone_to_idx.json\", \"r\") as f:\n",
    "    phone_to_idx = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m talk_id \u001b[39m=\u001b[39m file\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m.stm\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m phone_counters[talk_id] \u001b[39m=\u001b[39m [\u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(phone_to_idx)\n\u001b[0;32m----> 7\u001b[0m dataset \u001b[39m=\u001b[39m TEDLIUMRelease2SpecificTalkDataset(\n\u001b[1;32m      8\u001b[0m     identifier_to_phones_file_path\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mphones/ted2_normalized_phones_no_bcl.json\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      9\u001b[0m     subset\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     10\u001b[0m     vocab_file_path\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mvocabs/libri-light_10h.json\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     11\u001b[0m     talk_id\u001b[39m=\u001b[39;49mtalk_id,\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m _, _, _, _, _, _, phones \u001b[39min\u001b[39;00m dataset:\n\u001b[1;32m     14\u001b[0m     \u001b[39mfor\u001b[39;00m phone \u001b[39min\u001b[39;00m phones:\n",
      "File \u001b[0;32m/n/work3/shibutani/ASR/projects/phoneme-balanced-poc/step1/data.py:338\u001b[0m, in \u001b[0;36mTEDLIUMRelease2SpecificTalkDataset.__init__\u001b[0;34m(self, talk_id, identifier_to_phones_file_path, subset, root, vocab_file_path, sampling_rate)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m    330\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    331\u001b[0m     talk_id: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    336\u001b[0m     sampling_rate: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m16000\u001b[39m,\n\u001b[1;32m    337\u001b[0m ):\n\u001b[0;32m--> 338\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset \u001b[39m=\u001b[39m TEDLIUMRelease2SpecificTalkBase(\n\u001b[1;32m    339\u001b[0m         subset\u001b[39m=\u001b[39;49msubset, identifier_to_phones_file_path\u001b[39m=\u001b[39;49midentifier_to_phones_file_path, root\u001b[39m=\u001b[39;49mroot, talk_id\u001b[39m=\u001b[39;49mtalk_id\n\u001b[1;32m    340\u001b[0m     )\n\u001b[1;32m    341\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampling_rate \u001b[39m=\u001b[39m sampling_rate\n\u001b[1;32m    342\u001b[0m     \u001b[39m# only for normalization of input\u001b[39;00m\n",
      "File \u001b[0;32m/n/work3/shibutani/ASR/projects/phoneme-balanced-poc/step1/data.py:212\u001b[0m, in \u001b[0;36mTEDLIUMRelease2SpecificTalkBase.__init__\u001b[0;34m(self, talk_id, identifier_to_phones_file_path, root, subset)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_talk_id \u001b[39m=\u001b[39m talk_id\n\u001b[1;32m    211\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(identifier_to_phones_file_path, \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m--> 212\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39midentifier_to_phones \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39;49mload(f)\n\u001b[1;32m    214\u001b[0m stm_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_path, \u001b[39m\"\u001b[39m\u001b[39mstm\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    216\u001b[0m files \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mlistdir(stm_path)\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/json/__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(fp, \u001b[39m*\u001b[39m, \u001b[39mcls\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, object_hook\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, parse_float\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    275\u001b[0m         parse_int\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, parse_constant\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, object_pairs_hook\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw):\n\u001b[1;32m    276\u001b[0m     \u001b[39m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[39m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[39m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     \u001b[39mreturn\u001b[39;00m loads(fp\u001b[39m.\u001b[39;49mread(),\n\u001b[1;32m    294\u001b[0m         \u001b[39mcls\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mcls\u001b[39;49m, object_hook\u001b[39m=\u001b[39;49mobject_hook,\n\u001b[1;32m    295\u001b[0m         parse_float\u001b[39m=\u001b[39;49mparse_float, parse_int\u001b[39m=\u001b[39;49mparse_int,\n\u001b[1;32m    296\u001b[0m         parse_constant\u001b[39m=\u001b[39;49mparse_constant, object_pairs_hook\u001b[39m=\u001b[39;49mobject_pairs_hook, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[39m=\u001b[39m s\u001b[39m.\u001b[39mdecode(detect_encoding(s), \u001b[39m'\u001b[39m\u001b[39msurrogatepass\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_decoder\u001b[39m.\u001b[39;49mdecode(s)\n\u001b[1;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, s, _w\u001b[39m=\u001b[39mWHITESPACE\u001b[39m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m     \u001b[39m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[39m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_decode(s, idx\u001b[39m=\u001b[39;49m_w(s, \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mend())\n\u001b[1;32m    338\u001b[0m     end \u001b[39m=\u001b[39m _w(s, end)\u001b[39m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[39mif\u001b[39;00m end \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(s):\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/json/decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[39m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[39ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[39mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    350\u001b[0m \n\u001b[1;32m    351\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 353\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    355\u001b[0m     \u001b[39mraise\u001b[39;00m JSONDecodeError(\u001b[39m\"\u001b[39m\u001b[39mExpecting value\u001b[39m\u001b[39m\"\u001b[39m, s, err\u001b[39m.\u001b[39mvalue) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "phone_counters = {}\n",
    "stm_dir_path = \"datasets/TEDLIUM_release2/train/stm/\"\n",
    "for file in sorted(os.listdir(stm_dir_path)):\n",
    "    if file.endswith(\".stm\"):\n",
    "        talk_id = file.replace(\".stm\", \"\")\n",
    "        phone_counters[talk_id] = [0] * len(phone_to_idx)\n",
    "        dataset = TEDLIUMRelease2SpecificTalkDataset(\n",
    "            identifier_to_phones_file_path=\"phones/ted2_normalized_phones_no_bcl.json\",\n",
    "            subset=\"train\",\n",
    "            vocab_file_path=\"vocabs/libri-light_10h.json\",\n",
    "            talk_id=talk_id,\n",
    "        )\n",
    "        for _, _, _, _, _, _, phones in dataset:\n",
    "            for phone in phones:\n",
    "                if phone is not None:\n",
    "                    phone_counters[talk_id][phone_to_idx[phone]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_dists = {}\n",
    "for talk_id, phone_counter in phone_counters.items():\n",
    "    phone_counter = np.array(phone_counter, dtype=np.float32)\n",
    "    phone_counter += 1e-8\n",
    "    total = sum(phone_counter)\n",
    "    phone_dists[talk_id] = [count / total for count in phone_counter]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "libri_phone_counts = [0] * len(phone_to_idx)\n",
    "for i in range(len(libri_light_dataset)):\n",
    "    phones = libri_light_dataset[i][-1]\n",
    "    for phone in phones:\n",
    "        if phone is not None:\n",
    "            libri_phone_counts[phone_to_idx[phone]] += 1\n",
    "libri_phone_counts = np.array(libri_phone_counts, dtype=np.float32)\n",
    "libri_phone_distribute = (libri_phone_counts + 1e-8) / sum(libri_phone_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"phones/tedlium2_phone_distributes.pkl\", \"rb\") as f:\n",
    "    tedlium2_phone_distributes = pickle.load(f)\n",
    "with open(\"phones/tedlium2_phone_counters.pkl\", \"rb\") as f:\n",
    "    tedlium2_phone_counters = pickle.load(f)\n",
    "with open(\"phones/libri_phone_distribute.pkl\", \"rb\") as f:\n",
    "    libri_phone_distribute = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_kl_divergence(p, q):\n",
    "    p = np.array(p)\n",
    "    q = np.array(q)\n",
    "    return np.sum(p * np.log(p / q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00%\n",
      "74.74%\n",
      "77.15%\n",
      "78.62%\n",
      "80.60%\n",
      "87.99%\n",
      "90.19%\n"
     ]
    }
   ],
   "source": [
    "sampled_talk_ids = set()\n",
    "not_sampled_talk_ids = set(tedlium2_phone_distributes.keys())\n",
    "sampled_phone_counts = np.zeros(len(phone_to_idx), dtype=np.float32)\n",
    "sampled_duration = 0\n",
    "TARGET_DURATION = 600\n",
    "while sampled_duration < TARGET_DURATION:\n",
    "    print(f\"{sampled_duration/ TARGET_DURATION * 100:.2f}%\")\n",
    "    max_kl = 0\n",
    "    max_kl_talk_id = None\n",
    "    for talk_id in list(not_sampled_talk_ids):\n",
    "        if sum(tedlium2_phone_counters[talk_id]) < 100:\n",
    "            not_sampled_talk_ids.remove(talk_id)\n",
    "            continue\n",
    "        sampled_phone_counts_copy = sampled_phone_counts + np.array(tedlium2_phone_counters[talk_id])\n",
    "        sampled_phone_distribute_copy = (sampled_phone_counts_copy + 1e-8) / sum(sampled_phone_counts_copy)\n",
    "        kl_divergence = calculate_kl_divergence(sampled_phone_distribute_copy, libri_phone_distribute)\n",
    "        if kl_divergence > max_kl:\n",
    "            max_kl = kl_divergence\n",
    "            max_kl_talk_id = talk_id\n",
    "    if max_kl_talk_id is not None:\n",
    "        sampled_talk_ids.add(max_kl_talk_id)\n",
    "        not_sampled_talk_ids.remove(max_kl_talk_id)\n",
    "        sampled_phone_counts += np.array(tedlium2_phone_counters[max_kl_talk_id])\n",
    "        \n",
    "        sampled_dataset = TEDLIUMRelease2SpecificTalkDataset(\n",
    "            identifier_to_phones_file_path=\"phones/ted2_normalized_phones_no_bcl.json\",\n",
    "            subset=\"train\",\n",
    "            vocab_file_path=\"vocabs/libri-light_10h.json\",\n",
    "            talk_id=max_kl_talk_id,\n",
    "        )\n",
    "        for i in range(len(sampled_dataset)):\n",
    "            duration = sampled_dataset[i][2].item() / 16000\n",
    "            sampled_duration += duration\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "for talk_id in sampled_talk_ids:\n",
    "    dataset = TEDLIUMRelease2SpecificTalkDataset(\n",
    "        identifier_to_phones_file_path=\"phones/ted2_normalized_phones_no_bcl.json\",\n",
    "        subset=\"train\",\n",
    "        vocab_file_path=\"vocabs/libri-light_10h.json\",\n",
    "        talk_id=talk_id,\n",
    "    )\n",
    "    datasets.append(dataset)\n",
    "dataset = torch.utils.data.ConcatDataset(datasets)\n",
    "with open(\"tedlium2_difficult_600.pkl\", \"wb\") as f:\n",
    "    pickle.dump(dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "656.3999999999996"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e822874ab5bf40d8e254332eebb695e7fa04bbc22c17addc03c9268ee429b8b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
