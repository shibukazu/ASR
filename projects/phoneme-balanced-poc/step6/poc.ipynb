{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import LibriLightDataset\n",
    "import json\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = LibriLightDataset(\n",
    "    subset=\"9h\",\n",
    "    identifier_to_phones_file_path=\"phones/librispeech_normalized_phones_no_bcl.json\",\n",
    "    vocab_file_path=\"vocabs/libri-light_9h.json\"\n",
    ")\n",
    "test_dataset = LibriLightDataset(\n",
    "    subset=\"1h\",\n",
    "    identifier_to_phones_file_path=\"phones/librispeech_normalized_phones_no_bcl.json\",\n",
    "    vocab_file_path=\"vocabs/libri-light_9h.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_phonemes = set(\n",
    "    [\"aa\",\n",
    "    \"ae\",\n",
    "    \"ah\",\n",
    "    \"aw\",\n",
    "    \"ay\",\n",
    "    \"b\",\n",
    "    \"ch\",\n",
    "    \"d\",\n",
    "    \"dh\",\n",
    "    \"dx\",\n",
    "    \"eh\",\n",
    "    \"axr\",\n",
    "    \"ey\",\n",
    "    \"f\",\n",
    "    \"g\",\n",
    "    \"bcl\",\n",
    "    \"hh\",\n",
    "    \"ih\",\n",
    "    \"iy\",\n",
    "    \"jh\",\n",
    "    \"k\",\n",
    "    \"el\",\n",
    "    \"em\",\n",
    "    \"en\",\n",
    "    \"eng\",\n",
    "    \"ow\",\n",
    "    \"oy\",\n",
    "    \"p\",\n",
    "    \"r\",\n",
    "    \"s\",\n",
    "    \"sh\",\n",
    "    \"t\",\n",
    "    \"th\",\n",
    "    \"uh\",\n",
    "    \"uw\",\n",
    "    \"v\",\n",
    "    \"w\",\n",
    "    \"y\",\n",
    "    \"z\",]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_to_idx = {phone: idx for idx, phone in enumerate(target_phonemes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tf_idf(dataset: torch.utils.data.Dataset, phone_to_idx: dict, target_phones: set):\n",
    "    df = np.zeros(39, dtype=np.float32)\n",
    "    tf = np.zeros((len(dataset), 39), dtype=np.float32)\n",
    "    for idx in range(len(dataset)):\n",
    "        print(f\"{idx / len(dataset) * 100:.2f}%\", end=\"\\r\")\n",
    "        phones = dataset[idx][-1]\n",
    "        unique_phones = set(phones)\n",
    "        for target_phone in list(target_phones):\n",
    "            if target_phone in unique_phones:\n",
    "                df[phone_to_idx[target_phone]] += 1\n",
    "        for phone in phones:\n",
    "            if phone is not None:\n",
    "                tf[idx, phone_to_idx[phone]] += 1\n",
    "        tf[idx] = tf[idx] / len(phones)\n",
    "\n",
    "    df = df / len(dataset)\n",
    "    df += 1e-8\n",
    "    idf = np.log(1 / df)\n",
    "\n",
    "    return tf * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.65%\r"
     ]
    }
   ],
   "source": [
    "train_tf_idf = calculate_tf_idf(train_dataset, phone_to_idx, target_phonemes)\n",
    "test_tf_idf = calculate_tf_idf(test_dataset, phone_to_idx, target_phonemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.65%\r"
     ]
    }
   ],
   "source": [
    "not_sampled_indices = set(range(len(train_dataset)))\n",
    "sampled_indices = set()\n",
    "for idx in range(len(test_dataset)):\n",
    "    print(f\"{idx / len(test_dataset) * 100:.2f}%\", end=\"\\r\")\n",
    "    test_sample = test_tf_idf[idx]\n",
    "    similarities = {}\n",
    "    for sample_idx in not_sampled_indices:\n",
    "        train_sample = train_tf_idf[sample_idx]\n",
    "        similaritiy = cos_sim(test_sample, train_sample)\n",
    "        similarities[sample_idx] = similaritiy\n",
    "\n",
    "    max_similaritiy_idx = max(similarities, key=similarities.get)\n",
    "    sampled_indices.add(max_similaritiy_idx)\n",
    "    not_sampled_indices.remove(max_similaritiy_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(set(sampled_indices)) == len(sampled_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_train_dataset = torch.utils.data.Subset(train_dataset, list(sampled_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"sampled_train_dataset.pkl\", \"wb\") as f:\n",
    "    pickle.dump(sampled_train_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_duration = 0.\n",
    "for idx in range(len(sampled_train_dataset)):\n",
    "    duration = sampled_train_dataset[idx][2] / 16000\n",
    "    total_duration += duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duration of sampled dataset: 63.47 min\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total duration of sampled dataset: {total_duration / 60:.2f} min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3808.1145)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1025,\n",
       " tensor([-0.0016, -0.0020, -0.0101,  ..., -0.0012, -0.0058, -0.0128]),\n",
       " tensor(125120),\n",
       " tensor([ 7, 23, 14,  7, 27, 25, 14,  7,  8, 27, 28,  8, 24, 24, 11,  6, 27, 11,\n",
       "          6, 27, 14,  0,  7, 16, 14, 20, 20, 10, 27,  0, 19, 26, 11,  3, 15, 27,\n",
       "          7, 23, 24, 19, 16, 15, 23, 27, 19,  3, 27,  7, 23,  8, 27, 19,  7, 23,\n",
       "          8, 24, 27,  6, 11,  1,  8, 27, 11, 28, 27,  6, 23,  8, 27,  0, 23, 14,\n",
       "          3, 15,  8,  6, 27, 23,  8, 24, 27, 26, 11,  3,  1, 27, 26, 14,  3, 10,\n",
       "         27, 26, 19, 24,  8, 27,  7, 11, 26,  8,  6, 27,  7, 23,  8, 24,  8, 27,\n",
       "         17, 19,  3, 13,  7, 27, 18,  8, 27, 14,  3, 10,  7, 23, 11,  3, 15, 27,\n",
       "         20,  8, 28,  7,  4]),\n",
       " tensor(131),\n",
       " \"that kate ferris is actually coming through on the other side if she changes her mind many more times there won't be anything left\\n\",\n",
       " 6415,\n",
       " 100596,\n",
       " 18,\n",
       " ['dh',\n",
       "  'ae',\n",
       "  't',\n",
       "  'k',\n",
       "  'ey',\n",
       "  't',\n",
       "  'f',\n",
       "  'eh',\n",
       "  'r',\n",
       "  'ih',\n",
       "  's',\n",
       "  'ih',\n",
       "  'z',\n",
       "  'ae',\n",
       "  'k',\n",
       "  'ch',\n",
       "  'el',\n",
       "  'iy',\n",
       "  'k',\n",
       "  'ah',\n",
       "  'em',\n",
       "  'ih',\n",
       "  'eng',\n",
       "  'th',\n",
       "  'r',\n",
       "  'uw',\n",
       "  'aa',\n",
       "  'en',\n",
       "  'dh',\n",
       "  'iy',\n",
       "  'ah',\n",
       "  'dh',\n",
       "  'axr',\n",
       "  's',\n",
       "  'ay',\n",
       "  'd',\n",
       "  'ih',\n",
       "  'f',\n",
       "  'sh',\n",
       "  'iy',\n",
       "  'ch',\n",
       "  'ey',\n",
       "  'en',\n",
       "  'jh',\n",
       "  'ih',\n",
       "  'z',\n",
       "  'hh',\n",
       "  'axr',\n",
       "  'em',\n",
       "  'ay',\n",
       "  'en',\n",
       "  'd',\n",
       "  'em',\n",
       "  'eh',\n",
       "  'en',\n",
       "  'iy',\n",
       "  'em',\n",
       "  'aa',\n",
       "  'r',\n",
       "  't',\n",
       "  'ay',\n",
       "  'em',\n",
       "  'z',\n",
       "  'dh',\n",
       "  'eh',\n",
       "  'r',\n",
       "  'w',\n",
       "  'ow',\n",
       "  'en',\n",
       "  't',\n",
       "  'b',\n",
       "  'iy',\n",
       "  'eh',\n",
       "  'en',\n",
       "  'iy',\n",
       "  'th',\n",
       "  'ih',\n",
       "  'eng',\n",
       "  'el',\n",
       "  'eh',\n",
       "  'f',\n",
       "  't'])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tf_idf_over_ds(dataset: torch.utils.data.Dataset, phone_to_idx: dict, target_phones: set):\n",
    "    df = np.zeros(39, dtype=np.float32)\n",
    "    tf = np.zeros(39, dtype=np.float32)\n",
    "\n",
    "    for idx in range(len(dataset)):\n",
    "        print(f\"{idx / len(dataset) * 100:.2f}%\", end=\"\\r\")\n",
    "        phones = dataset[idx][-1]\n",
    "        unique_phones = set(phones)\n",
    "        for target_phone in list(target_phones):\n",
    "            if target_phone in unique_phones:\n",
    "                df[phone_to_idx[target_phone]] += 1\n",
    "        for phone in phones:\n",
    "            if phone is not None:\n",
    "                tf[phone_to_idx[phone]] += 1\n",
    "                \n",
    "    tf = tf / tf.sum()\n",
    "\n",
    "    df = df / len(dataset)\n",
    "    df += 1e-8\n",
    "    idf = np.log(1 / df)\n",
    "\n",
    "    return tf * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.65%\r"
     ]
    }
   ],
   "source": [
    "test_tf_idf_over_ds = calculate_tf_idf_over_ds(test_dataset, phone_to_idx, target_phonemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tf\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "sampled_duration = 0\n",
    "limit_duration = 600\n",
    "not_sampled_indices = set(range(len(train_dataset)))\n",
    "sampled_indices = set()\n",
    "while sampled_duration < limit_duration:\n",
    "    print(f\"{sampled_duration / limit_duration * 100:.2f}%\", end=\"\\r\")\n",
    "    similarities = {}\n",
    "    for idx in not_sampled_indices:\n",
    "        sampled_indices_copy = sampled_indices.copy()\n",
    "        sampled_indices_copy.add(idx)\n",
    "        sampled_subset = torch.utils.data.Subset(sampled_train_dataset, list(sampled_indices_copy))\n",
    "        sampled_tf_idf_over_ds = calculate_tf_idf_over_ds(sampled_subset, phone_to_idx, target_phonemes)\n",
    "        similarity = cos_sim(test_tf_idf_over_ds, sampled_tf_idf_over_ds)\n",
    "        similarities[idx] = similarity\n",
    "    \n",
    "    max_similaritiy_idx = max(similarities, key=similarities.get)\n",
    "    sampled_indices.add(max_similaritiy_idx)\n",
    "    not_sampled_indices.remove(max_similaritiy_idx)\n",
    "    sampled_duration += train_dataset[max_similaritiy_idx][2] / 16000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.zeros(3)\n",
    "b = a.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e822874ab5bf40d8e254332eebb695e7fa04bbc22c17addc03c9268ee429b8b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
