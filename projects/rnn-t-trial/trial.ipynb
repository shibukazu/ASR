{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shibutani/miniconda3/envs/py39/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.functional import pad\n",
    "import torch.nn\n",
    "from data import YesNoDataset, LibriSpeechDataset, get_dataloader\n",
    "from model import CausalConformerModel\n",
    "from torchaudio.functional import rnnt_loss\n",
    "from torch.nn.functional import log_softmax\n",
    "from torchmetrics.functional import char_error_rate\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:4\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport json\\nlibri_train_dataset = LibriSpeechDataset(\\n    root=\"datasets/\",\\n    split=\"train\",\\n    vocab_file_path=\"vocabs/librispeech_train_960h.json\",\\n)\\nidx_to_audio_sec = {}\\nfor i in range(len(libri_train_dataset)):\\n    print(f\"{i / len(libri_train_dataset) * 100:.2f}%\", end=\"\\r\")\\n    audio_sec = libri_train_dataset[i][-1]\\n    idx_to_audio_sec[i] = audio_sec\\nwith open(\"librispeech_train_960h_idx_to_audio_sec.json\", \"w\") as f:\\n    json.dump(idx_to_audio_sec, f)\\n\\nimport json\\nlibri_dev_other_dataset = LibriSpeechDataset(\\n    root=\"datasets/\",\\n    split=\"dev-other\",\\n    vocab_file_path=\"vocabs/librispeech_dev_other.json\",\\n)\\nidx_to_audio_sec = {}\\nfor i in range(len(libri_dev_other_dataset)):\\n    print(f\"{i / len(libri_dev_other_dataset) * 100:.2f}%\", end=\"\\r\")\\n    audio_sec = libri_dev_other_dataset[i][-1]\\n    idx_to_audio_sec[i] = audio_sec\\nwith open(\"librispeech_dev_other_idx_to_audio_sec.json\", \"w\") as f:\\n    json.dump(idx_to_audio_sec, f)\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import json\n",
    "libri_train_dataset = LibriSpeechDataset(\n",
    "    root=\"datasets/\",\n",
    "    split=\"train\",\n",
    "    vocab_file_path=\"vocabs/librispeech_train_960h.json\",\n",
    ")\n",
    "idx_to_audio_sec = {}\n",
    "for i in range(len(libri_train_dataset)):\n",
    "    print(f\"{i / len(libri_train_dataset) * 100:.2f}%\", end=\"\\r\")\n",
    "    audio_sec = libri_train_dataset[i][-1]\n",
    "    idx_to_audio_sec[i] = audio_sec\n",
    "with open(\"librispeech_train_960h_idx_to_audio_sec.json\", \"w\") as f:\n",
    "    json.dump(idx_to_audio_sec, f)\n",
    "\n",
    "import json\n",
    "libri_dev_other_dataset = LibriSpeechDataset(\n",
    "    root=\"datasets/\",\n",
    "    split=\"dev-other\",\n",
    "    vocab_file_path=\"vocabs/librispeech_dev_other.json\",\n",
    ")\n",
    "idx_to_audio_sec = {}\n",
    "for i in range(len(libri_dev_other_dataset)):\n",
    "    print(f\"{i / len(libri_dev_other_dataset) * 100:.2f}%\", end=\"\\r\")\n",
    "    audio_sec = libri_dev_other_dataset[i][-1]\n",
    "    idx_to_audio_sec[i] = audio_sec\n",
    "with open(\"librispeech_dev_other_idx_to_audio_sec.json\", \"w\") as f:\n",
    "    json.dump(idx_to_audio_sec, f)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport json\\nyesno_train_dataset = YesNoDataset(\\n    wav_dir_path=\"datasets/waves_yesno/\",\\n    model_sample_rate=16000,\\n    split=\"train\"\\n)\\nidx_to_audio_sec = {}\\nfor i in range(len(yesno_train_dataset)):\\n    print(f\"{i / len(yesno_train_dataset) * 100:.2f}%\", end=\"\\r\")\\n    audio_sec = yesno_train_dataset[i][-1]\\n    idx_to_audio_sec[i] = audio_sec\\nwith open(\"yesno_train_idx_to_audio_sec.json\", \"w\") as f:\\n    json.dump(idx_to_audio_sec, f)\\nimport json\\nyesno_dev_dataset = YesNoDataset(\\n    wav_dir_path=\"datasets/waves_yesno/\",\\n    model_sample_rate=16000,\\n    split=\"dev\"\\n)\\nidx_to_audio_sec = {}\\nfor i in range(len(yesno_dev_dataset)):\\n    print(f\"{i / len(yesno_dev_dataset) * 100:.2f}%\", end=\"\\r\")\\n    audio_sec = yesno_dev_dataset[i][-1]\\n    idx_to_audio_sec[i] = audio_sec\\nwith open(\"yesno_dev_idx_to_audio_sec.json\", \"w\") as f:\\n    json.dump(idx_to_audio_sec, f)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import json\n",
    "yesno_train_dataset = YesNoDataset(\n",
    "    wav_dir_path=\"datasets/waves_yesno/\",\n",
    "    model_sample_rate=16000,\n",
    "    split=\"train\"\n",
    ")\n",
    "idx_to_audio_sec = {}\n",
    "for i in range(len(yesno_train_dataset)):\n",
    "    print(f\"{i / len(yesno_train_dataset) * 100:.2f}%\", end=\"\\r\")\n",
    "    audio_sec = yesno_train_dataset[i][-1]\n",
    "    idx_to_audio_sec[i] = audio_sec\n",
    "with open(\"yesno_train_idx_to_audio_sec.json\", \"w\") as f:\n",
    "    json.dump(idx_to_audio_sec, f)\n",
    "import json\n",
    "yesno_dev_dataset = YesNoDataset(\n",
    "    wav_dir_path=\"datasets/waves_yesno/\",\n",
    "    model_sample_rate=16000,\n",
    "    split=\"dev\"\n",
    ")\n",
    "idx_to_audio_sec = {}\n",
    "for i in range(len(yesno_dev_dataset)):\n",
    "    print(f\"{i / len(yesno_dev_dataset) * 100:.2f}%\", end=\"\\r\")\n",
    "    audio_sec = yesno_dev_dataset[i][-1]\n",
    "    idx_to_audio_sec[i] = audio_sec\n",
    "with open(\"yesno_dev_idx_to_audio_sec.json\", \"w\") as f:\n",
    "    json.dump(idx_to_audio_sec, f)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = YesNoDataset(\n",
    "    wav_dir_path=\"datasets/waves_yesno/\",\n",
    "    model_sample_rate=16000,\n",
    "    split=\"train\"\n",
    ")\n",
    "dataloader = get_dataloader(\n",
    "    dataset,\n",
    "    batch_sec=60,\n",
    "    num_workers=1,\n",
    "    pad_idx=dataset.pad_idx,\n",
    "    pin_memory=True,\n",
    "    audio_sec_file_path=\"audio_secs/yesno_train_idx_to_audio_sec.json\"\n",
    ")\n",
    "\n",
    "idx_to_token = dataset.idx_to_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch Prepare: 100%|██████████| 48/48 [00:00<00:00, 30066.70it/s]\n",
      "Batch Prepare: 100%|██████████| 48/48 [00:00<00:00, 57260.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.89999999999999\n",
      "61.089999999999996\n",
      "62.24\n",
      "61.489999999999995\n",
      "47.690000000000005\n",
      "[[45, 27, 17, 40, 10, 42, 9, 5, 6, 46], [18, 32, 2, 44, 13, 8, 30, 0, 15, 28], [19, 21, 22, 26, 41, 36, 29, 33, 47, 14], [12, 20, 11, 25, 38, 34, 24, 31, 16, 37], [7, 3, 1, 43, 23, 35, 4, 39]]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "sampled_idx = []\n",
    "for bidx, bx, by, bx_len, by_len, baudio_sec in dataloader:\n",
    "    sampled_idx.append(bidx)\n",
    "    print(sum(baudio_sec))\n",
    "print(sampled_idx)\n",
    "sampled_indices = [item for sublist in sampled_idx for item in sublist]\n",
    "print(len(set(sampled_indices)) == len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "libri_dataset = LibriSpeechDataset(\n",
    "    root=\"./datasets\",\n",
    "    split=\"dev-other\",\n",
    "    resampling_rate=16000,\n",
    "    vocab_file_path=\"vocabs/librispeech_train_960h.json\",\n",
    "    audio_sec_file_path=\"audio_secs/librispeech_dev_other_idx_to_audio_sec.json\",\n",
    ")\n",
    "libri_dataloader = get_dataloader(\n",
    "    libri_dataset,\n",
    "    batch_sec=100,\n",
    "    num_workers=1,\n",
    "    pad_idx=libri_dataset.pad_idx,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch Prepare: 100%|██████████| 2864/2864 [00:00<00:00, 368662.12it/s]\n",
      "Batch Prepare: 100%|██████████| 2864/2864 [00:00<00:00, 227165.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104.3\n",
      "108.2000625\n",
      "103.50493749999998\n",
      "103.26500000000001\n",
      "101.39\n",
      "100.86000000000001\n",
      "102.2900625\n",
      "100.165\n",
      "110.26000000000002\n",
      "102.50499999999998\n",
      "106.365\n",
      "113.99493750000002\n",
      "105.58\n",
      "100.73000000000003\n",
      "103.325\n",
      "100.08506249999999\n",
      "102.78\n",
      "103.66\n",
      "101.485\n",
      "101.24000000000001\n",
      "103.45500000000001\n",
      "100.51\n",
      "113.58999999999997\n",
      "110.14500000000001\n",
      "100.25500000000001\n",
      "104.57\n",
      "103.60499999999999\n",
      "101.91\n",
      "104.29\n",
      "106.86500000000001\n",
      "120.35\n",
      "104.61999999999999\n",
      "100.48500000000003\n",
      "112.49506249999999\n",
      "108.15499999999999\n",
      "100.465\n",
      "107.035\n",
      "107.25493750000001\n",
      "107.21993749999997\n",
      "101.815\n",
      "109.61500000000001\n",
      "100.24000000000001\n",
      "105.28500000000001\n",
      "111.63499999999999\n",
      "101.805\n",
      "101.22499999999998\n",
      "100.03993749999998\n",
      "109.87493750000002\n",
      "106.05000000000001\n",
      "102.0700625\n",
      "109.9050625\n",
      "103.905\n",
      "100.59\n",
      "106.32993749999997\n",
      "102.845\n",
      "112.18506249999999\n",
      "101.06500000000001\n",
      "102.505\n",
      "105.1250625\n",
      "105.08\n",
      "100.13499999999999\n",
      "102.13499999999999\n",
      "105.44500000000001\n",
      "102.36500000000001\n",
      "100.9399375\n",
      "104.895\n",
      "106.13\n",
      "107.345\n",
      "109.03500000000001\n",
      "102.57006249999999\n",
      "102.26493749999999\n",
      "100.285\n",
      "102.47493749999998\n",
      "101.785\n",
      "116.44999999999999\n",
      "122.435\n",
      "109.15999999999998\n",
      "100.59\n",
      "103.46000000000002\n",
      "106.61\n",
      "109.08999999999999\n",
      "104.77999999999999\n",
      "102.90499999999999\n",
      "113.3\n",
      "100.7\n",
      "118.505\n",
      "103.57000000000001\n",
      "106.67999999999998\n",
      "101.66\n",
      "101.60493749999999\n",
      "102.12500000000001\n",
      "100.3400625\n",
      "101.565\n",
      "101.86000000000001\n",
      "103.29499999999999\n",
      "115.74\n",
      "108.255\n",
      "102.915\n",
      "102.59\n",
      "102.17500000000003\n",
      "104.02\n",
      "102.91506249999999\n",
      "108.88\n",
      "103.50999999999999\n",
      "100.64500000000002\n",
      "100.93006249999999\n",
      "102.09\n",
      "104.17500000000001\n",
      "103.80499999999998\n",
      "111.25506250000001\n",
      "102.27000000000001\n",
      "112.175\n",
      "104.71000000000001\n",
      "104.315\n",
      "103.1850625\n",
      "101.76506250000001\n",
      "105.405\n",
      "102.64\n",
      "100.19006250000001\n",
      "104.95499999999997\n",
      "105.065\n",
      "108.35999999999999\n",
      "101.35493750000002\n",
      "108.2800625\n",
      "106.125\n",
      "108.81000000000002\n",
      "102.04499999999999\n",
      "101.67\n",
      "108.045\n",
      "101.53\n",
      "105.22\n",
      "101.660125\n",
      "111.505\n",
      "101.58500000000001\n",
      "103.465\n",
      "108.54493750000003\n",
      "111.13\n",
      "106.91999999999999\n",
      "100.635\n",
      "105.725\n",
      "106.94000000000001\n",
      "101.93499999999997\n",
      "100.335\n",
      "106.8599375\n",
      "108.07493749999999\n",
      "104.0\n",
      "100.42500000000001\n",
      "100.77\n",
      "109.73\n",
      "103.96\n",
      "113.83993749999999\n",
      "124.86993749999999\n",
      "106.32000000000001\n",
      "100.13499999999999\n",
      "101.69506250000002\n",
      "100.645\n",
      "111.13499999999998\n",
      "106.43000000000002\n",
      "109.9349375\n",
      "104.095\n",
      "104.165\n",
      "104.97999999999999\n",
      "102.17999999999999\n",
      "115.82006249999999\n",
      "100.83999999999997\n",
      "101.295\n",
      "103.32\n",
      "101.02006250000001\n",
      "102.69000000000001\n",
      "107.16500000000002\n",
      "102.84499999999998\n",
      "103.18499999999999\n",
      "104.9800625\n",
      "103.54500000000002\n",
      "104.6750625\n",
      "57.30500000000001\n",
      "[[1699, 89, 2325, 1087, 522, 1505, 361, 1416, 1401, 504, 1956, 1710, 2451, 2573, 973, 216], [1642, 113, 940, 2387, 1690, 1851, 1756, 124, 285, 1839, 848, 317, 905, 768], [1993, 1018, 2453, 183, 1037, 524, 494, 410, 1305, 614, 24, 1186, 1484, 1307, 1228, 1012, 807], [1313, 1025, 331, 111, 665, 2292, 2151, 1190, 1320, 1274, 2215, 2004, 2816, 2319, 2261, 1270, 1965, 1169], [2064, 165, 2269, 1463, 1739, 382, 2500, 1155, 2634, 2790, 2712, 2589, 1994, 2122], [1201, 100, 226, 779, 1883, 857, 2407, 2655, 1231, 2231, 1720, 1319, 2554, 1937], [2278, 1341, 2317, 1475, 236, 240, 2141, 2686, 1040, 635, 2694, 557, 1103, 1167, 2253], [411, 2125, 650, 631, 1989, 1894, 18, 1526, 2778, 241, 1694, 102, 2460, 841, 1494, 2276, 1746, 2754], [2535, 1890, 47, 1652, 2283, 2169, 2448, 2348, 1296, 193, 2137, 2541, 1100, 805, 764, 1371, 2521, 833], [2843, 2591, 2069, 2679, 1359, 1045, 2512, 1860, 1566, 1646, 1172, 1999, 832, 10, 1948, 464, 2360], [1027, 352, 2440, 886, 598, 2104, 1014, 1543, 997, 1522, 626, 2333, 20, 677, 526, 2532, 1564], [2551, 1199, 2775, 810, 2086, 1547, 1904, 1239, 1610, 485, 2332, 1881, 663, 941, 838, 2845, 1028, 2723, 2676, 920], [1857, 2470, 937, 963, 2096, 751, 1861, 487, 1430, 1057, 622, 842, 1659, 140, 394, 1117, 2543, 2110, 998], [2288, 1681, 772, 404, 1586, 2364, 710, 2126, 1917, 2766, 1629, 1792, 2114, 1008, 1207, 1582], [630, 2454, 996, 873, 328, 199, 1335, 1671, 2329, 1456, 1738], [1617, 2724, 48, 1639, 49, 152, 1144, 2308, 196, 1417, 1286, 2813, 1432, 374, 2239, 2281, 2857, 2629], [1840, 2297, 1767, 1265, 1346, 2739, 1302, 2658, 312, 725, 406, 1532, 2338, 1697, 2271, 1549, 1942, 1179, 228, 672, 1900], [1255, 872, 2648, 1292, 1441, 1501, 1019, 1220, 2312, 1981, 591, 2406, 1866], [1870, 304, 1162, 1577, 56, 2290, 2514, 396, 923, 2414, 2179, 1821, 120, 271, 755, 66], [1835, 1469, 656, 942, 463, 91, 422, 12, 472, 827, 2305, 2737, 853, 1742, 1920, 1700], [2756, 2196, 637, 1173, 429, 970, 2861, 1601, 1071, 2622, 700, 938, 2065, 1109, 759, 1022, 1141], [87, 248, 2245, 703, 895, 1968, 2574, 2265, 2672, 2761, 2084, 777, 2009, 1029, 2320, 1966, 1196, 2621, 1841], [611, 763, 737, 2316, 1940, 303, 671, 2395, 51, 866, 1836, 1802, 2807, 2731, 1277, 1879, 791, 2060, 675], [1077, 2402, 1687, 1567, 233, 2750, 732, 384, 55, 1627, 2443, 547, 820, 601, 657, 1985, 2057, 1751], [1322, 1898, 2713, 783, 107, 155, 1794, 313, 1369, 540, 2549, 532, 1604], [1421, 2562, 889, 1175, 1833, 457, 2212, 27, 1660, 2837, 1379, 265, 2080, 347, 1770], [1192, 162, 1500, 2763, 740, 483, 324, 2088, 14, 2720, 2434, 930, 1753], [2353, 2608, 1206, 1020, 863, 2365, 2464, 735, 1974, 865, 2010, 881, 615, 1769, 1491, 1512, 188], [286, 1745, 2824, 345, 784, 871, 1353, 1345, 1334, 2424], [82, 2430, 2412, 947, 255, 130, 1326, 1712, 2753, 696, 2487, 1471, 569, 787, 116, 1372, 1048, 1344], [921, 2609, 2427, 215, 1287, 2618, 302, 2507, 1208, 2314, 330, 518, 2041, 1142, 935, 2023, 2788], [608, 1356, 1542, 1049, 1222, 2802, 2270, 1102, 416, 1569, 1466, 137, 2073, 2384, 2757, 334, 2115, 2431, 2469], [2025, 2733, 2236, 571, 1518, 708, 1711, 1733, 582, 948, 1773, 2569, 2822], [1703, 2666, 2105, 1498, 967, 2398, 1953, 1971, 648, 26, 2602, 1578, 237], [2102, 1688, 505, 2783, 802, 1645, 2690, 344, 205, 1789, 1161, 2467, 826, 1384, 200, 1516, 2291, 1845], [785, 506, 217, 2654, 2526, 1439, 260, 2190, 2162, 760, 574, 2846, 733, 297, 918], [697, 2006, 566, 2146, 685, 93, 1076, 2274, 281], [2458, 2450, 846, 2186, 2762, 673, 2555, 1785, 2606, 2530, 21, 2295, 247, 351, 1649, 655, 1811, 1943, 1215, 1511, 946], [2491, 649, 1452, 1930, 1448, 175, 219, 2116, 595, 822, 2620, 391, 915], [836, 2725, 2619, 379, 2045, 2721, 1357, 1216, 2109, 2748, 1327, 2545, 894, 1232, 2199, 4, 1202, 1397, 296], [789, 2538, 62, 977, 2653, 1355, 1826, 2576, 1235, 131, 1242, 1757, 2525, 888, 117, 2842, 799, 166, 2187], [2471, 2645, 1957, 1084, 2246, 490, 1847, 2300, 1525, 988, 1415, 366], [2659, 1995, 1941, 1648, 438, 319, 50, 1729, 1474, 2581, 1224, 1225, 565, 2135, 2735, 1728, 340, 1303], [2520, 2795, 891, 902, 2053, 2108, 1184, 1740, 446, 678, 1918, 2094, 545], [523, 2665, 2590, 2615, 2841, 37, 53, 2492, 808, 1933, 2043, 1587, 2250, 1593, 1312, 1294, 2355, 2107], [1997, 1862, 769, 2635, 235, 405, 144, 1790, 1267, 1871, 1637, 1764, 1760, 2219, 2286, 1946, 161, 1166, 2691], [2630, 2575, 986, 2345, 1093, 689, 2138, 980, 1164, 880, 342, 1747, 1927, 176, 2624, 1163, 1961, 1759, 2472], [1318, 1625, 1831, 1750, 1692, 2527, 2599, 954, 2657, 1590, 2103, 2637, 179, 153, 1072], [1034, 706, 917, 864, 1696, 2852, 1091, 1797, 2106, 717, 1675, 325, 2378, 1358, 1288], [854, 307, 1521, 223, 528, 2341, 306, 2321, 909, 1815, 1921, 666, 1873, 357, 916, 658], [548, 914, 2390, 333, 1552, 242, 2765, 1258, 110, 1015, 1528, 97, 525, 2150, 515, 793, 1806], [341, 680, 2449, 1776, 618, 2425, 1123, 475, 9, 652, 42, 606, 1657, 1674, 2327, 1406, 2728, 2821, 450, 1031], [1289, 1538, 95, 1105, 2743, 577, 381, 2835, 533, 435, 1882, 2702, 1203, 468, 2673, 1295, 2260, 407, 356], [749, 2706, 1612, 177, 2678, 2081, 2156, 1409, 2160, 683, 883, 2661, 1056, 1550, 2092, 249, 1822], [642, 2794, 2567, 1297, 570, 1124, 60, 932, 2118, 1982, 2082, 2173, 2192, 2820, 647, 2785], [2782, 2133, 1364, 1514, 1434, 1975, 2537, 1991, 64, 2650, 1682, 581, 171, 679, 2740, 1486], [88, 1200, 103, 782, 2478, 2825, 2662, 994, 803, 2580, 1440, 267, 882, 1106, 572, 2669], [896, 310, 1537, 884, 568, 616, 2805, 1237, 1388, 530, 251, 1573, 1892, 1240, 2732, 600, 2844], [2225, 829, 2776, 1574, 75, 2593, 16, 1891, 1140, 553, 5, 1152, 1555, 2742, 393, 1366, 2005, 1719], [2587, 1622, 1017, 1934, 1342, 112, 2692, 2258, 1055, 206, 1419, 1170, 1531, 1895, 1950, 2331, 1540, 711, 1865, 2121], [2238, 2237, 2083, 1248, 2055, 766, 424, 2758, 1669, 245, 437, 1634, 939, 619, 2781, 2432], [817, 2423, 473, 418, 2809, 1458, 369, 957, 2561, 1926, 731, 794, 1385, 1869, 1872, 1427], [856, 1348, 1068, 1223, 1058, 1515, 2640, 1609, 1774, 1819, 1618, 1584, 1227, 1931, 367, 2089, 1171], [1400, 2812, 1038, 389, 1880, 517, 1565, 246, 1115, 2350, 1504, 2, 149, 449, 326, 1395, 2000, 1074], [2643, 1145, 1330, 552, 910, 520, 417, 2034, 1477, 1762, 699, 408, 2068, 1945, 469], [2505, 904, 1849, 1673, 2039, 2202, 434, 1329, 1088, 2681, 1786, 2767, 1453, 875, 359, 497], [2322, 1908, 1349, 2296, 519, 2476, 2235, 646, 1686, 1264, 1887, 776, 2273, 1073, 1107, 0], [1259, 778, 1122, 1396, 2026, 1470, 445, 230, 164, 1158, 1214, 259, 1306], [2481, 597, 544, 1092, 2085, 2259, 1529, 730, 2373, 2343, 636, 2002, 1393, 2050, 2076], [2012, 1888, 1663, 2389, 734, 2217, 2054, 559, 1539, 2328, 690, 172, 294, 931, 466, 2806, 2266], [2548, 2349, 1814, 503, 716, 1744, 1546, 338, 2515, 2745, 1461, 2483, 1413, 1183, 761, 118, 1502, 2827, 1478, 258], [586, 712, 2452, 433, 1846, 315, 610, 220, 1765, 343, 2022, 538, 1708, 1698, 2264, 2675, 1275, 2154], [234, 2707, 2117, 398, 92, 1350, 2062, 99, 1497, 1878, 125, 2204, 654, 1273, 1783, 798, 702, 1420], [2310, 2556, 2641, 273, 738, 543, 1853, 1737, 2147, 1362, 750, 481, 625, 847, 934, 1138], [1914, 7, 2764, 1116, 561, 268, 2550, 1701, 579, 224, 1829, 959, 1261, 1809, 253, 667], [1766, 159, 1301, 1969, 2863, 1595, 178, 2831, 2249, 1579, 2203, 1133, 906, 892, 2213, 2301, 2435, 1624], [489, 2175, 694, 2485, 2839, 2704, 628, 1632, 1150, 736, 612, 2224, 1338], [431, 2371, 1154, 707, 198, 2388, 2391, 2267, 1784, 2167, 1707, 2656, 2072, 739, 57, 1383, 2234, 2400, 2815, 409, 1467, 412], [182, 2059, 1188, 800, 1023, 1246, 718, 2194, 2363, 2358, 1159, 801, 815, 1620, 2342, 1859, 23, 1063], [1656, 2504, 1226, 2832, 1061, 142, 284, 2144, 453, 1085, 1010, 1278, 1591, 1046, 1075, 133, 2858, 2586], [578, 576, 1655, 1947, 1219, 2120, 1243, 19, 1568, 2416, 1643, 2709, 76, 320, 2410, 439, 644, 674, 86, 2600, 587, 2061, 22], [1136, 231, 1197, 2315, 1722, 276, 298, 390, 1381, 537, 2056, 757, 1743, 2277, 1876, 1051, 2178, 1315], [698, 1412, 1827, 465, 1033, 2603, 1972, 2405, 527, 2484, 1482, 1002], [2664, 995, 1592, 2377, 1664, 2553, 337, 1234, 2124, 1212, 754, 2294, 1576], [460, 280, 575, 2557, 2717, 843, 2703, 1043, 1923, 1635, 1506, 2152, 2585, 1363, 743, 2572, 400], [830, 1902, 2381, 61, 2380, 855, 1793, 2394, 106, 85, 2145, 1070, 2636, 2304, 2415], [1078, 2638, 2123, 1449, 1325, 839, 1249, 844, 1191, 300, 2473, 2421], [2232, 387, 2552, 1308, 1174, 2298, 1126, 363, 1300, 795, 627, 539, 2020, 531, 983], [2610, 2189, 1062, 924, 1864, 2468, 202, 1572, 420, 2038, 2303, 1996, 549], [811, 443, 321, 2140, 427, 1848, 2078, 877, 1734, 2163, 2457, 911, 1597, 1143, 2032], [376, 2444, 2508, 1730, 158, 691, 2214, 2823, 2511, 1998, 2613, 2685, 1060, 2223, 2718, 2399, 2087], [958, 1128, 536, 1036, 1210, 2417, 121, 2366, 1524, 907, 1906, 1796, 104, 796, 98, 2035], [71, 1454, 1583, 2700, 11, 1404, 1101, 1446, 2254, 551, 1254, 1445, 1496], [6, 925, 1863, 859, 1391, 2801, 550, 1431, 713, 1180, 2772, 558, 1187, 84, 903, 1394, 214], [1725, 2293, 868, 2018, 1684, 1718, 1752, 1108, 1377, 2161, 723, 981, 987], [1217, 39, 2040, 129, 495, 2205, 96, 1069, 1493, 283, 594, 818, 1221, 377, 101], [2596, 461, 2386, 653, 59, 1520, 229, 2070, 1903, 442, 824, 1813, 589, 455, 823, 1731, 2494, 555, 1480], [2547, 2710, 187, 1795, 1425, 897, 974, 1052, 2071, 2287, 2191, 2734, 1026, 2803, 2570, 1536, 936, 15], [908, 2437, 773, 2255, 1435, 1805, 2518, 2752, 2477, 621, 1194, 1104, 436, 513], [2808, 358, 1702, 991, 682, 1768, 2466, 2682, 2361, 1527, 2392, 975, 705, 151, 1360, 584, 2860], [687, 1218, 2495, 2522, 1523, 775, 309, 1683, 2408, 567, 108, 858, 583, 2436, 2090, 2651, 1987], [2577, 2447, 1979, 1668, 2337, 2698, 1647, 275, 1139, 277, 780, 1044, 1125, 2760, 1053, 45, 681, 1775], [470, 2335, 38, 139, 1387, 960, 1771, 474, 714, 2493, 184, 264, 620, 1204, 1557, 1408, 509, 2017, 2488, 2646, 432], [1778, 2180, 1147, 2475, 752, 292, 607, 2347, 1716, 1935, 29, 834, 203, 821, 1095, 535], [402, 1443, 1361, 1490, 2268, 1479, 2403, 350, 2148, 2744, 1005, 1755, 1928, 2383, 774, 462, 926], [1949, 1777, 1929, 239, 1628, 1211, 426, 641, 316, 1875, 452, 1233, 2442, 596, 1083, 1256], [2829, 1476, 1897, 1651, 999, 1820, 1570, 1854, 850, 2746, 2560, 1041, 900, 2311, 870], [2351, 1964, 1251, 814, 54, 1571, 2309, 2112, 2368, 127, 1130, 1545, 747, 397, 860], [2183, 2804, 2091, 1352, 32, 645, 602, 1619, 2142, 2598, 2197, 2252, 1485, 812, 1788, 2066, 154, 72, 1280], [1039, 2132, 971, 428, 1748, 1779, 1399, 529, 2607, 2164, 684], [94, 962, 290, 1316, 250, 806, 1157, 1402, 1959, 221, 1428, 1047, 1924, 2833], [695, 2711, 2153, 2419, 2558, 2131, 2828, 624, 493, 478, 348, 1024, 36, 135, 31, 746], [371, 1112, 295, 744, 1080, 720, 2098, 467, 1462, 1436, 270, 1487], [2438, 2251, 454, 2052, 2369, 2578, 2285, 269, 1003, 1984, 2024, 1706, 664, 354, 2605, 1311], [2461, 2074, 1581, 792, 261, 13, 2625, 985, 2058, 2594, 521, 2099, 1066, 2771, 1967, 1812, 1, 2370], [2617, 70, 2683, 1181, 1262, 2644, 167, 180, 2171, 1714, 1382, 508, 1607, 2696, 2862, 1611, 1332, 2313, 105, 2119, 1976, 2747], [2184, 2396, 372, 2326, 274, 2275, 1799, 2633, 605, 2693, 322, 1499, 2159, 929, 1589, 804, 2755, 2531, 388], [1818, 2397, 90, 835, 2817, 423, 722, 1236, 1798, 1059, 585, 1198, 2534, 1324, 949, 2284], [2226, 2158, 448, 148, 419, 952, 1097, 1042, 1304, 335, 1455, 1724, 1111, 349, 825], [134, 34, 2697, 514, 1689, 1473, 1713, 2533, 1588, 2729, 1544, 1678, 2357, 1616, 278], [210, 282, 965, 2001, 2668, 2516, 244, 484, 2128, 1004, 966, 440, 541, 1099, 2282, 2498, 556], [1685, 2211, 756, 2741, 972, 945, 65, 1955, 1134, 890, 1615, 2848, 1559, 2100, 1081, 2564], [2227, 2372, 327, 30, 1165, 222, 2340, 3, 2233, 927, 2588, 160, 1911, 1772, 1250, 1007, 2198, 1834, 498, 174, 332, 2722], [126, 1517, 204, 1561, 1877, 2262, 211, 562, 1721, 922, 2490, 1030, 1331], [1867, 1791, 709, 2517, 1374, 1121, 138, 1119, 1670, 128, 1633, 869, 1970, 2670, 1843, 8, 2542], [2524, 1279, 2519, 1481, 67, 1803, 1257, 762, 1298, 1704, 2716, 2779, 1658, 554, 2257, 311], [629, 851, 1562, 1035, 1992, 2272, 2243, 1370, 2046, 1726, 291, 2474, 456, 2674, 2797, 1838], [189, 2595, 2510, 984, 2242, 1009, 1082, 79, 2346, 990, 339, 2699, 1398, 1910, 2016, 2819, 828], [669, 2413, 1414, 2188, 840, 2404, 1177, 2800, 2859, 1513, 1241, 2382], [2352, 2318, 299, 2502, 1268, 2497, 603, 262, 1736, 1260, 809, 444, 2240, 758, 728, 1488, 2565, 943, 633, 305, 2263, 451, 1693, 2727], [1276, 1621, 753, 2385, 2456, 2063, 1114, 2015, 1723, 1983, 1178, 1901, 2571, 1378, 2028, 2075, 2631], [719, 2559, 1705, 1299, 2409, 1168, 150, 458, 1189, 2660, 563, 1340, 1368, 441, 362, 1936], [676, 1405, 964, 726, 1962, 1650, 414, 1193, 1662, 2579, 1665, 1858, 368, 1727, 28, 1390, 2509, 2420], [2362, 2210, 1086, 2714, 2155, 78, 2097, 1373, 1614, 928, 1182, 1780, 1754, 471, 992], [1000, 1781, 604, 2334, 2374, 2356, 2166, 1640, 2853, 2021, 1418, 2307, 1230, 415], [2496, 2810, 1013, 2568, 770, 1149, 845, 2482, 2738, 2540, 898, 1830, 1825, 2289, 862, 1641, 1321], [2854, 1001, 2113, 1535, 1376, 1548, 1451, 1679, 1429, 919, 2523, 1837, 212], [1654, 2375, 686, 2037, 2429, 114, 2773, 58, 208, 2182, 1603, 1113, 1424, 1986, 488], [375, 73, 499, 2013, 1842, 1343, 2207, 1613, 1392, 1032, 201, 156, 1328, 2687, 1317, 874, 2774, 729], [1054, 2855, 2751, 147, 2228, 2647, 1990, 2446, 2796, 2719, 289, 1422, 899, 2401], [2649, 901, 430, 651, 2791, 1912, 1893, 1958, 1913, 191, 1889, 2529, 1909, 2165, 1438], [1824, 2784, 1389, 510, 2067, 2566, 721, 1855, 1899, 378, 2367, 2136, 2708, 401, 1238, 1886, 1735, 1209], [2030, 1495, 688, 837, 1667, 1916, 308, 1333, 2157, 2489, 403, 1403, 329, 1575, 2143, 479, 2799, 640, 2200], [2336, 516, 1407, 1585, 976, 83, 1213, 2851, 122, 1919, 1952, 2499, 2422, 1988, 141], [1954, 599, 68, 2536, 816, 301, 2323, 1229, 136, 767, 2604, 1284, 989, 1808], [2208, 786, 1850, 2222, 2513, 2127, 1691, 1016, 1137, 1290, 1423, 2048, 2671, 1509, 2501, 1110], [2418, 2011, 953, 660, 370, 511, 2033, 1011, 1672, 662, 365, 209, 2546, 2302, 287, 1468], [2768, 256, 1749, 2663, 1339, 2612, 2047, 2130, 1978, 2241, 501, 2684, 336, 2462, 819, 218, 2247, 1153, 1804], [2149, 1050, 1263, 293, 813, 546, 1269, 878, 950, 2216, 1323, 2049, 1856, 1661, 912], [421, 2503, 1160, 2592, 1442, 2715, 1541, 491, 1282, 2793, 2627, 1336, 2244, 2181, 982, 2623], [1556, 486, 1551, 232, 143, 2680, 186, 2632, 2736, 2170, 2463, 279, 2601, 2168, 745], [1605, 238, 2209, 1090, 1067, 1079, 2786, 727, 1905, 413, 383, 1444, 1447, 1907, 1580, 496], [163, 1310, 2769, 1380, 849, 170, 213, 425, 2051, 1600, 2220, 742, 1354, 1874, 1437, 1281, 2726, 1375], [1291, 1717, 119, 1623, 1715, 1563, 2445, 500, 2393, 670, 459, 207, 2428], [564, 580, 1631, 1064, 44, 617, 254, 476, 2642, 1963, 661, 2174, 2279, 2248, 25, 2324], [1472, 399, 2201, 1823, 1021, 263, 314, 978, 724, 2789, 197, 266, 969, 1118, 1006], [2798, 123, 69, 1365, 632, 364, 1608, 2626, 1507, 323, 2354, 2111, 592, 2616, 2480, 1636, 1205, 1098, 1386], [2455, 1782, 512, 741, 2759, 169, 1489, 1337, 2218, 1096, 1464, 951], [2614, 2787, 190, 2306, 252, 1309, 2003, 2027, 1271, 1932, 109, 781, 2007, 2830, 2639, 2506, 2230, 225], [2459, 74, 1245, 2847, 638, 1939, 643, 534, 2426, 2376, 1131, 507, 1185, 2811], [1120, 1787, 480, 1680, 885, 115, 1741, 2563, 2705, 613, 1807, 1459, 2582, 17, 1465, 2840], [1800, 1433, 1885, 395, 2036, 2042, 1761, 771, 81, 353, 609, 1065, 560, 1272], [2079, 1630, 748, 1195, 623, 1283, 243, 1534, 2229, 831, 887, 318, 2344, 2095, 1253, 1151], [346, 2465, 1508, 227, 1599, 1244, 1351, 2826, 1977, 173, 385, 1314, 1606, 639, 1411, 1980, 1868, 1127, 2584, 765, 955], [1089, 2652, 692, 2486, 993, 1503, 1426, 288, 2441, 2029, 43, 181, 1558, 1695, 2008, 961, 355], [2695, 1176, 1801, 2339, 52, 2379, 447, 1602, 2479, 145, 40, 588, 1852, 2299, 2628], [168, 790, 1973, 2439, 2093, 157, 2730, 2139, 659, 2701, 2539, 2176, 257, 272, 2838, 1638, 1598, 386, 1530], [1347, 41, 593, 2770, 634, 1758, 797, 2195, 1148, 1832, 1844, 1533, 590, 33], [35, 132, 2280, 2780, 2834, 1951, 185, 1510, 2433, 1285, 1925, 2836, 2077, 893, 1816, 2528, 46], [1666, 1732, 2172, 146, 2583, 1367, 944, 1132, 2019, 195, 2411, 2597, 1410, 1594], [1884, 788, 693, 2792, 933, 968, 715, 2101, 80, 1457, 1146, 2031, 1676, 380, 2206, 194, 1644, 1944, 2256], [2850, 2193, 1553, 1247, 192, 668, 876, 1519, 2611, 1129, 1492, 1828, 1653, 573, 2129, 373], [1810, 1817, 2134, 2689, 492, 704, 1156, 77, 477, 1677, 2221, 1709, 2014, 1094, 2818, 2185, 1483, 2777, 2330, 2177], [1938, 2677, 852, 2849, 1460, 1896, 979, 1266, 1450, 2749, 1596, 482, 2544, 867, 2856, 502, 861], [879, 2044, 701, 956, 542, 913, 1252, 1922, 1915, 1293, 392, 2688], [63, 2359, 1135, 1626, 1960, 360, 1554, 2814, 1560, 1763, 2667]]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "sampled_idx = []\n",
    "for bidx, bx, by, bx_len, by_len, baudio_sec in libri_dataloader:\n",
    "    sampled_idx.append(bidx)\n",
    "    print(sum(baudio_sec))\n",
    "print(sampled_idx)\n",
    "sampled_indices = [item for sublist in sampled_idx for item in sublist]\n",
    "print(len(set(sampled_indices)) == len(libri_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpt_path = \"./cpts/yesno_causal_conformer/836b576aac7744c2857c00ae170f7b91/model_YesNo_80.pth\"\n",
    "with open(cpt_path, \"rb\") as f:\n",
    "    cpt = torch.load(f, map_location=DEVICE)\n",
    "\n",
    "model = CausalConformerModel(\n",
    "    vocab_size=8,\n",
    "    encoder_input_size=40,\n",
    "    encoder_subsampled_input_size=128,\n",
    "    encoder_num_conformer_blocks=1,\n",
    "    encoder_ff_hidden_size=128,\n",
    "    encoder_conv_hidden_size=128,\n",
    "    encoder_conv_kernel_size=16,\n",
    "    encoder_mha_num_heads=4,\n",
    "    encoder_dropout=0,\n",
    "    encoder_subsampling_kernel_size1=3,\n",
    "    encoder_subsampling_stride1=2,\n",
    "    encoder_subsampling_kernel_size2=3,\n",
    "    encoder_subsampling_stride2=2,\n",
    "    encoder_num_previous_frames=\"all\",\n",
    "    embedding_size=64,\n",
    "    predictor_hidden_size=64,\n",
    "    predictor_num_layers=1,\n",
    "    jointnet_hidden_size=64,\n",
    "    blank_idx=dataset.blank_idx,\n",
    "    decoder_buffer_size=4,\n",
    ").to(DEVICE)\n",
    "model.load_state_dict(cpt[\"model\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  2],\n",
       " [0,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  3,\n",
       "  4],\n",
       " [0,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  2],\n",
       " [0,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  3,\n",
       "  4],\n",
       " [3,\n",
       "  4,\n",
       "  5,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  3,\n",
       "  4],\n",
       " [3,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  2],\n",
       " [3,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  3,\n",
       "  4],\n",
       " [0,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  3,\n",
       "  4]]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "benc_input, bpred_input, benc_input_length, bpred_input_length, baudio_sec = next(iter(dataloader))\n",
    "benc_input = benc_input.to(DEVICE)\n",
    "bhyp_token_indices = model.streaming_greedy_inference(benc_input, benc_input_length)\n",
    "bhyp_token_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "bans_token_indices = [\n",
    "    bpred_input[i, : bpred_input_length[i]].tolist() for i in range(bpred_input.shape[0])\n",
    "]\n",
    "bhyp_text = [\n",
    "    \"\".join([idx_to_token[idx] for idx in hyp_token_indices])\n",
    "    for hyp_token_indices in bhyp_token_indices\n",
    "]\n",
    "bans_text = [\n",
    "    \"\".join([idx_to_token[idx] for idx in ans_token_indices])\n",
    "    for ans_token_indices in bans_token_indices\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyp: yes no no no no no yes yes\n",
      "ans: yes no no no no no yes yes\n",
      "\n",
      "hyp: yes yes no no yes no yes no\n",
      "ans: yes yes no no yes no yes no\n",
      "\n",
      "hyp: yes no yes yes yes yes no yes\n",
      "ans: yes no yes yes yes yes no yes\n",
      "\n",
      "hyp: yes yes yes yes no yes no no\n",
      "ans: yes yes yes yes no yes no no\n",
      "\n",
      "hyp: no no yes yes yes no no no\n",
      "ans: no no yes yes yes no no no\n",
      "\n",
      "hyp: no yes yes yes yes yes yes yes\n",
      "ans: no yes yes yes yes yes yes yes\n",
      "\n",
      "hyp: no yes no yes yes yes no no\n",
      "ans: no yes no yes yes yes no no\n",
      "\n",
      "hyp: yes no yes yes yes no yes no\n",
      "ans: yes no yes yes yes no yes no\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(bhyp_text)):\n",
    "    print(f\"hyp: {bhyp_text[i]}\")\n",
    "    print(f\"ans: {bans_text[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [False, False,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [False, False, False,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [False, False, False, False,  True,  True,  True,  True,  True,  True],\n",
      "        [False, False, False, False, False,  True,  True,  True,  True,  True],\n",
      "        [False, False, False, False, False, False,  True,  True,  True,  True],\n",
      "        [False, False, False, False, False, False, False,  True,  True,  True],\n",
      "        [False, False, False, False, False, False, False, False,  True,  True],\n",
      "        [False, False, False, False, False, False, False, False, False,  True],\n",
      "        [False, False, False, False, False, False, False, False, False, False]])\n",
      "tensor([[False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(3, 10, 5)\n",
    "input_length=x.shape[1]\n",
    "future_mask = torch.triu(torch.ones(input_length, input_length), diagonal=1).bool()\n",
    "print(future_mask)\n",
    "NUM_PREVIOUS_FRAMES = \"all\"\n",
    "# mask before NUM_PREVIOUS_FRAMES\n",
    "input_length=x.shape[1]\n",
    "if NUM_PREVIOUS_FRAMES == \"all\":\n",
    "    previous_mask = torch.zeros(input_length, input_length).bool()\n",
    "else:\n",
    "    previous_mask=torch.tril(torch.ones(input_length, input_length), diagonal=-(NUM_PREVIOUS_FRAMES+1)).bool()\n",
    "print(previous_mask)\n",
    "future_and_previous_mask = torch.logical_or(future_mask, previous_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future_and_previous_mask"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e822874ab5bf40d8e254332eebb695e7fa04bbc22c17addc03c9268ee429b8b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
