{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shibutani/miniconda3/envs/py39/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tokenizer import SentencePieceTokenizer\n",
    "from model import CausalConformerModel\n",
    "from data import LibriSpeechDataset, get_dataloader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZER_MODEL_FILE_PATH = \"./vocabs/librispeech_1024_bpe.model\"\n",
    "DATASET_JSON_FILE_PATH = \"./json/librispeech_train-clean-100.json\"\n",
    "MODEL_FILE_PATH = \"./artifacts/librispeech_small_check/f9c410c7599f48ca99e541afadcc4ebd/artifacts/model_25.pth\"\n",
    "DEVICE = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch Prepare: 100%|██████████| 28539/28539 [00:00<00:00, 342325.33it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SentencePieceTokenizer(\n",
    "    model_file_path=TOKENIZER_MODEL_FILE_PATH,\n",
    ")\n",
    "dataset = LibriSpeechDataset(\n",
    "    resampling_rate=16000,\n",
    "    tokenizer=tokenizer,\n",
    "    json_file_path=DATASET_JSON_FILE_PATH,\n",
    ")\n",
    "dataloader = get_dataloader(\n",
    "    dataset,\n",
    "    batch_sec=30,\n",
    "    num_workers=8,\n",
    "    pad_idx=tokenizer.pad_token_id,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(MODEL_FILE_PATH, \"rb\") as f:\n",
    "    cpt = torch.load(f)\n",
    "model_state = cpt[\"model\"]\n",
    "model_args = cpt[\"model_args\"]\n",
    "model = CausalConformerModel(**model_args).to(DEVICE)\n",
    "model.load_state_dict(model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyp: and drive me to invent falsehoods and replied but all this was suddenly brought to an end for the time came when all such considerations were disrearted and there was no further question of honor when my patience gave way and the secret of my heart became known abroad\n",
      "ans: and drive me to invent falsehoods in reply but all this was suddenly brought to an end for the time came when all such considerations were disregarded and there was no further question of honour when my patience gave way and the secret of my heart became known abroad\n",
      "\n",
      "hyp: that would be turning your visit into an evil indeed wherever you are you should always be contented but especially at home because there you must spend the most of your time i did not quite like\n",
      "ans: that would be turning your visit into an evil indeed wherever you are you should always be contented but especially at home because there you must spend the most of your time i did not quite like at breakfast\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, benc_input, bpred_input, benc_input_length, bpred_input_length, baudio_sec = next(iter(dataloader))\n",
    "benc_input = benc_input.to(DEVICE)\n",
    "bpred_input = bpred_input.to(DEVICE)\n",
    "\n",
    "bhyp_token_indices = model.streaming_greedy_inference(\n",
    "    enc_inputs=benc_input, enc_input_lengths=benc_input_length\n",
    ")\n",
    "bans_token_indices = [\n",
    "        bpred_input[i, : bpred_input_length[i]].tolist() for i in range(bpred_input.shape[0])\n",
    "]\n",
    "bhyp_text = tokenizer.batch_token_ids_to_text(bhyp_token_indices)\n",
    "bans_text = tokenizer.batch_token_ids_to_text(bans_token_indices)\n",
    "for hyp, ans in zip(bhyp_text, bans_text):\n",
    "    print(f\"hyp: {hyp}\")\n",
    "    print(f\"ans: {ans}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353 best hypothesis: and dried me to advant falsehoods in reply but all this was suddenly brought to an end for the time came when all such considerations were disregarded and there was no further question of honor when my patience gave way and the secret of my heart became known abroad\n",
      "364 best hypothesis: that would be turning your visit into an evil indeed wherever you are you should always be contented but especially at home because there you must spend the most of your time i did not quite like at breakfast\n"
     ]
    }
   ],
   "source": [
    "bhyp_nbest_token_indices = model.beamsearch_inference(\n",
    "    enc_inputs=benc_input, enc_input_lengths=benc_input_length, tokenizer=tokenizer, beam_size=2\n",
    ")\n",
    "bans_token_indices = [\n",
    "        bpred_input[i, : bpred_input_length[i]].tolist() for i in range(bpred_input.shape[0])\n",
    "]\n",
    "bans_text = tokenizer.batch_token_ids_to_text(bans_token_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans: and drive me to invent falsehoods in reply but all this was suddenly brought to an end for the time came when all such considerations were disregarded and there was no further question of honour when my patience gave way and the secret of my heart became known abroad\n",
      "hyp0: and dried me to advant falsehoods in reply but all this was suddenly brought to an end for the time came when all such considerations were disregarded and there was no further question of honor when my patience gave way and the secret of my heart became known abroad\n",
      "hyp1: and dried me to advant falsehoods in reply but all this was suddenly brought to an end for the time came when all such considerations were disregarded and there was no further question of honor when my patience gave way and the secret of my heart became known abro\n",
      "ans: that would be turning your visit into an evil indeed wherever you are you should always be contented but especially at home because there you must spend the most of your time i did not quite like at breakfast\n",
      "hyp0: that would be turning your visit into an evil indeed wherever you are you should always be contented but especially at home because there you must spend the most of your time i did not quite like at breakfast\n",
      "hyp1: that would be turning your visit into an evil indeed wherever you are you should always be contented but especially at home because there you must spend the most of your time i did not quite like at breakfaste\n"
     ]
    }
   ],
   "source": [
    "for i, ans in enumerate(bans_text):\n",
    "    print(f\"ans: {ans}\")\n",
    "    for j, hyp_tokens in enumerate(bhyp_nbest_token_indices[i]):\n",
    "        hyp = tokenizer.token_ids_to_text(hyp_tokens)\n",
    "        print(f\"hyp{j}: {hyp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e822874ab5bf40d8e254332eebb695e7fa04bbc22c17addc03c9268ee429b8b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
