{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shibutani/miniconda3/envs/py39/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from modules.decoders.ctc import greedy_decoder\n",
    "from quantizer import Quantizer\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "from transformers import Wav2Vec2CTCTokenizer, Wav2Vec2FeatureExtractor\n",
    "import re\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchaudio.datasets.TEDLIUM(\n",
    "    root=\"datasets\",\n",
    "    release=\"release2\",\n",
    "    subset=\"train\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0107, -0.0120, -0.0123,  ..., -0.0042, -0.0031, -0.0022]]),\n",
       " 16000,\n",
       " 'today because of\\n',\n",
       " '911Mothers_2010W',\n",
       " '911Mothers_2010W',\n",
       " '<o,f0,female>')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "contra_dict = {}\n",
    "contra_dict[\"are not\"] = \"aren 't\"\n",
    "contra_dict[\"can not\"] = \"can 't\"\n",
    "sentence = \"you are not master.\"\n",
    "sentence2 = \"I am you 're it 's we 'll 'd\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0.00% of the dataset\n",
      "Found 0 contractions so far\n",
      "Processed 0.11% of the dataset\n",
      "Found 28 contractions so far\n",
      "Processed 0.22% of the dataset\n",
      "Found 61 contractions so far\n",
      "Processed 0.32% of the dataset\n",
      "Found 87 contractions so far\n",
      "Processed 0.43% of the dataset\n",
      "Found 88 contractions so far\n",
      "Processed 0.54% of the dataset\n",
      "Found 103 contractions so far\n",
      "Processed 0.65% of the dataset\n",
      "Found 115 contractions so far\n",
      "Processed 0.75% of the dataset\n",
      "Found 166 contractions so far\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [39], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m contractions_count \u001b[39m=\u001b[39m defaultdict(\u001b[39mlambda\u001b[39;00m: \u001b[39m0\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfor\u001b[39;00m n, example \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataset):\n\u001b[1;32m      3\u001b[0m     \u001b[39m# show progress\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[39mif\u001b[39;00m n \u001b[39m%\u001b[39m \u001b[39m100\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m      5\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mProcessed \u001b[39m\u001b[39m{\u001b[39;00mn \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(dataset) \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m% of the dataset\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/torchaudio/datasets/tedlium.py:173\u001b[0m, in \u001b[0;36mTEDLIUM.__getitem__\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[39m\"\"\"Load the n-th sample from the dataset.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \n\u001b[1;32m    166\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[39m    tuple: ``(waveform, sample_rate, transcript, talk_id, speaker_id, identifier)``\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    172\u001b[0m fileid, line \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_filelist[n]\n\u001b[0;32m--> 173\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_tedlium_item(fileid, line, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_path)\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/torchaudio/datasets/tedlium.py:139\u001b[0m, in \u001b[0;36mTEDLIUM._load_tedlium_item\u001b[0;34m(self, fileid, line, path)\u001b[0m\n\u001b[1;32m    136\u001b[0m     talk_id, _, speaker_id, start_time, end_time, identifier, transcript \u001b[39m=\u001b[39m transcript\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m6\u001b[39m)\n\u001b[1;32m    138\u001b[0m wave_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(path, \u001b[39m\"\u001b[39m\u001b[39msph\u001b[39m\u001b[39m\"\u001b[39m, fileid)\n\u001b[0;32m--> 139\u001b[0m waveform, sample_rate \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_audio(wave_path \u001b[39m+\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ext_audio, start_time\u001b[39m=\u001b[39;49mstart_time, end_time\u001b[39m=\u001b[39;49mend_time)\n\u001b[1;32m    141\u001b[0m \u001b[39mreturn\u001b[39;00m (waveform, sample_rate, transcript, talk_id, speaker_id, identifier)\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/torchaudio/datasets/tedlium.py:161\u001b[0m, in \u001b[0;36mTEDLIUM._load_audio\u001b[0;34m(self, path, start_time, end_time, sample_rate)\u001b[0m\n\u001b[1;32m    157\u001b[0m end_time \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mfloat\u001b[39m(end_time) \u001b[39m*\u001b[39m sample_rate)\n\u001b[1;32m    159\u001b[0m kwargs \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mframe_offset\u001b[39m\u001b[39m\"\u001b[39m: start_time, \u001b[39m\"\u001b[39m\u001b[39mnum_frames\u001b[39m\u001b[39m\"\u001b[39m: end_time \u001b[39m-\u001b[39m start_time}\n\u001b[0;32m--> 161\u001b[0m \u001b[39mreturn\u001b[39;00m torchaudio\u001b[39m.\u001b[39;49mload(path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/torchaudio/backend/sox_io_backend.py:152\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filepath, frame_offset, num_frames, normalize, channels_first, format)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[39mreturn\u001b[39;00m torchaudio\u001b[39m.\u001b[39m_torchaudio\u001b[39m.\u001b[39mload_audio_fileobj(\n\u001b[1;32m    150\u001b[0m             filepath, frame_offset, num_frames, normalize, channels_first, \u001b[39mformat\u001b[39m)\n\u001b[1;32m    151\u001b[0m     filepath \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mfspath(filepath)\n\u001b[0;32m--> 152\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49mtorchaudio\u001b[39m.\u001b[39;49msox_io_load_audio_file(\n\u001b[1;32m    153\u001b[0m     filepath, frame_offset, num_frames, normalize, channels_first, \u001b[39mformat\u001b[39;49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "contractions_count = defaultdict(lambda: 0)\n",
    "for n, example in enumerate(dataset):\n",
    "    # show progress\n",
    "    if n % 100 == 0:\n",
    "        print(f\"Processed {n / len(dataset) * 100:.2f}% of the dataset\")\n",
    "        print(f\"Found {len(contractions_count)} contractions so far\")\n",
    "\n",
    "\n",
    "    sentence = example[2]\n",
    "    sentence = sentence.replace(\"\\n\", \"\")\n",
    "    word_list = sentence.split(\" \")\n",
    "    for i, word in enumerate(word_list):\n",
    "        if \"'\" in word:\n",
    "            # 前方向に「 ' 」を含まない単語が登場するまで移動し、その単語の位置をstart_idxとする\n",
    "            idx = i - 1\n",
    "            while idx >= 0:\n",
    "                if \"'\" not in word_list[idx]:\n",
    "                    break\n",
    "                idx -= 1\n",
    "            start_idx = idx\n",
    "            # 後方向に「 ' 」を含まない単語が登場するまで移動し、その単語の位置をend_idxとする\n",
    "            idx = i + 1\n",
    "            while idx < len(word_list):\n",
    "                if \"'\" not in word_list[idx]:\n",
    "                    break\n",
    "                idx += 1\n",
    "            end_idx = idx\n",
    "\n",
    "            contractions_count[\" \".join(word_list[start_idx:end_idx])] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Union\n",
    "\n",
    "import torchaudio\n",
    "from torch import Tensor\n",
    "from torch.hub import download_url_to_file\n",
    "from torch.utils.data import Dataset\n",
    "from torchaudio.datasets.utils import extract_archive\n",
    "from collections import defaultdict\n",
    "\n",
    "class TEDLIUMRelase2(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        talk_id: str,\n",
    "        root: str = \"datasets/TEDLIUM_release2\",\n",
    "        subset: str = \"train\",\n",
    "    ) -> None:\n",
    "        \n",
    "        self._path = os.path.join(root, subset)\n",
    "        # Create list for all samples\n",
    "        self._lines = None\n",
    "        self._talk_id = None\n",
    "        stm_path = os.path.join(self._path, \"stm\")\n",
    "\n",
    "        files = os.listdir(stm_path)\n",
    "        if talk_id + \".stm\" in files:\n",
    "            stm_path = os.path.join(self._path, \"stm\", talk_id + \".stm\")\n",
    "            self._talk_id = talk_id\n",
    "            with open(stm_path) as f:\n",
    "                l = len(f.readlines())\n",
    "                self._lines = list(range(l))\n",
    "        else:\n",
    "            raise ValueError(\"talk_id is not valid\")\n",
    "        # Create dict path for later read\n",
    "        self._dict_path = os.path.join(root, \"TEDLIUM.152k.dic\")\n",
    "        self._phoneme_dict = None\n",
    "\n",
    "    def _load_tedlium_item(self, line: int) -> Tuple[Tensor, int, str, int, int, int]:\n",
    "        \"\"\"Loads a TEDLIUM dataset sample given a file name and corresponding sentence name.\n",
    "\n",
    "        Args:\n",
    "            line (int): Line identifier for the sample inside the text file\n",
    "\n",
    "        Returns:\n",
    "            (Tensor, int, str, int, int, int):\n",
    "            ``(waveform, sample_rate, transcript, talk_id, speaker_id, identifier)``\n",
    "        \"\"\"\n",
    "        transcript_path = os.path.join(self._path, \"stm\", self._talk_id) + \".stm\"\n",
    "        with open(transcript_path) as f:\n",
    "            transcript = f.readlines()[line]\n",
    "            talk_id, _, speaker_id, start_time, end_time, identifier, transcript = transcript.split(\" \", 6)\n",
    "\n",
    "        wave_path = os.path.join(self._path, \"sph\", self._talk_id) + \".sph\"\n",
    "        waveform, sample_rate = self._load_audio(wave_path, start_time=start_time, end_time=end_time)\n",
    "        return (waveform, sample_rate, transcript, talk_id, speaker_id, identifier)\n",
    "\n",
    "    def _load_audio(self, path: str, start_time: float, end_time: float, sample_rate: int = 16000) -> [Tensor, int]:\n",
    "        \"\"\"Default load function used in TEDLIUM dataset, you can overwrite this function to customize functionality\n",
    "        and load individual sentences from a full ted audio talk file.\n",
    "\n",
    "        Args:\n",
    "            path (str): Path to audio file\n",
    "            start_time (int): Time in seconds where the sample sentence stars\n",
    "            end_time (int): Time in seconds where the sample sentence finishes\n",
    "            sample_rate (float, optional): Sampling rate\n",
    "\n",
    "        Returns:\n",
    "            [Tensor, int]: Audio tensor representation and sample rate\n",
    "        \"\"\"\n",
    "        start_time = int(float(start_time) * sample_rate)\n",
    "        end_time = int(float(end_time) * sample_rate)\n",
    "\n",
    "        kwargs = {\"frame_offset\": start_time, \"num_frames\": end_time - start_time}\n",
    "\n",
    "        return torchaudio.load(path, **kwargs)\n",
    "\n",
    "    def __getitem__(self, n: int) -> Tuple[Tensor, int, str, int, int, int]:\n",
    "        \"\"\"Load the n-th sample from the dataset.\n",
    "\n",
    "        Args:\n",
    "            n (int): The index of the sample to be loaded\n",
    "\n",
    "        Returns:\n",
    "            Tuple of the following items;\n",
    "\n",
    "            Tensor:\n",
    "                Waveform\n",
    "            int:\n",
    "                Sample rate\n",
    "            str:\n",
    "                Transcript\n",
    "            int:\n",
    "                Talk ID\n",
    "            int:\n",
    "                Speaker ID\n",
    "            int:\n",
    "                Identifier\n",
    "        \"\"\"\n",
    "        line = self._lines[n]\n",
    "        return self._load_tedlium_item(line)\n",
    "\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"TEDLIUM dataset custom function overwritting len default behaviour.\n",
    "\n",
    "        Returns:\n",
    "            int: TEDLIUM dataset length\n",
    "        \"\"\"\n",
    "        return len(self._lines)\n",
    "\n",
    "    @property\n",
    "    def phoneme_dict(self):\n",
    "        \"\"\"dict[str, tuple[str]]: Phonemes. Mapping from word to tuple of phonemes.\n",
    "        Note that some words have empty phonemes.\n",
    "        \"\"\"\n",
    "        # Read phoneme dictionary\n",
    "        if not self._phoneme_dict:\n",
    "            self._phoneme_dict = {}\n",
    "            with open(self._dict_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                for line in f.readlines():\n",
    "                    content = line.strip().split()\n",
    "                    self._phoneme_dict[content[0]] = tuple(content[1:])  # content[1:] can be empty list\n",
    "        return self._phoneme_dict.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TEDLIUMRelase2TextNormalized(talk_id=\"911Mothers_2010W\", text_normalizer=TextNormalizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0105, 0.0092, 0.0077,  ..., 0.0023, 0.0046, 0.0074]]),\n",
       " 16000,\n",
       " \"and i hope that someday we 'll all live together in peace and respecting each other this is what i wanted to say\",\n",
       " '911Mothers_2010W',\n",
       " '911Mothers_2010W',\n",
       " '<o,f0,female>')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e822874ab5bf40d8e254332eebb695e7fa04bbc22c17addc03c9268ee429b8b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
